{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6b6af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameshaberberger/Gitlab/gaussian-process/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "from pyro.contrib import gp\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "n_points = 10\n",
    "n_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c0b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def rbf_kernels(Z, length_scales, variances, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Compute independent RBF kernels per feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : tensor, shape (N, F)\n",
    "        Inducing point positions. Each column f corresponds to feature f.\n",
    "    length_scales : tensor, shape (F,)\n",
    "        Lengthscale for each feature.\n",
    "    variances : tensor, shape (F,)\n",
    "        Variance for each feature.\n",
    "    jitter : float\n",
    "        Diagonal stability term.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    K : tensor, shape (N, N, F)\n",
    "        K[:,:,f] is the RBF kernel for feature f.\n",
    "    \"\"\"\n",
    "    N, F = Z.shape\n",
    "\n",
    "    # (N,1,F) - (1,N,F) -> (N,N,F)\n",
    "    diffs = Z.unsqueeze(1) - Z.unsqueeze(0)\n",
    "    D2 = diffs.pow(2)  # squared distance for each feature\n",
    "\n",
    "    ls2 = length_scales.view(1, 1, F) ** 2\n",
    "    var = variances.view(1, 1, F)\n",
    "\n",
    "    K = var * torch.exp(-0.5 * D2 / ls2)\n",
    "\n",
    "    # add jitter along diagonals\n",
    "    eye = torch.eye(N, device=Z.device, dtype=Z.dtype).unsqueeze(-1)\n",
    "    K = K + jitter * eye\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb303a0",
   "metadata": {},
   "source": [
    "# Working Model(!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23dc18bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inducing_points_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m         inducing_points_loc = torch.tensor(-\u001b[32m3.\u001b[39m, device=device)\n\u001b[32m     10\u001b[39m         inducing_points_scale = torch.tensor(\u001b[32m3.\u001b[39m, device=device)\n\u001b[32m     11\u001b[39m         inducing_point_values = pyro.sample(\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minducing_point_values\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m             dist.Normal(\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m                 \u001b[43minducing_points_min\u001b[49m,\n\u001b[32m     15\u001b[39m                 inducing_points_max\n\u001b[32m     16\u001b[39m             )\n\u001b[32m     17\u001b[39m         )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Sample Different Kernels\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pyro.plate(\u001b[33m\"\u001b[39m\u001b[33mkernels\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m100\u001b[39m):\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Length Scales\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'inducing_points_min' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample Different Inducing Points\n",
    "inducing_points = pyro.param(\n",
    "    \"inducing_points\", \n",
    "    torch.linspace(-3, 3, n_points).expand(n_features, -1).clone()\n",
    ")\n",
    "\n",
    "with pyro.plate(\"inducing_points\", n_points):\n",
    "    with pyro.plate(\"features\", 100):\n",
    "        inducing_points_loc = torch.tensor(-3., device=device)\n",
    "        inducing_points_scale = torch.tensor(3., device=device)\n",
    "        inducing_point_values = pyro.sample(\n",
    "            \"inducing_point_values\",\n",
    "            dist.Normal(\n",
    "                inducing_points_min,\n",
    "                inducing_points_max\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Sample Different Kernels\n",
    "with pyro.plate(\"kernels\", 100):\n",
    "    # Length Scales\n",
    "    length_scale_loc = torch.tensor(1., device=device)\n",
    "    length_scale_scale = torch.tensor(1., device=device)\n",
    "    length_scales = pyro.sample(\n",
    "        \"length_scales\",\n",
    "        dist.Gamma(\n",
    "            length_scale_loc,\n",
    "            length_scale_scale\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Variances\n",
    "    variance_loc = torch.tensor(1., device=device)\n",
    "    variance_scale = torch.tensor(1., device=device)\n",
    "    variances = pyro.sample(\n",
    "        \"variances\",\n",
    "        dist.Gamma(\n",
    "            variance_loc,\n",
    "            variance_scale\n",
    "        )\n",
    "    )\n",
    "\n",
    "with pyro.plate(\"log_dispersion\"):\n",
    "    # Variances\n",
    "    log_dispersion_loc = torch.tensor(1., device=device)\n",
    "    log_dispersion_scale = torch.tensor(1., device=device)\n",
    "    log_dispersions = pyro.sample(\n",
    "        \"log_dispersions\",\n",
    "        dist.Gamma(\n",
    "            log_dispersion_loc,\n",
    "            log_dispersion_scale\n",
    "        )\n",
    "    )\n",
    "\n",
    "# We then evaluate the GP at each of the points.\n",
    "covariance_matrices = rbf_featurewise(inducing_points_x, length_scales, variances, jitter=1e-6)\n",
    "\n",
    "with pyro.plate(\"gp\", n_features):\n",
    "    f = pyro.sample(\n",
    "        \"gp\",\n",
    "        dist.MultivariateNormal(\n",
    "            inducing_point_values,\n",
    "        covariance_matrices       \n",
    "        )\n",
    "    )\n",
    "\n",
    "pyro.sample(\n",
    "    \"obs\",\n",
    "    dist.NegativeBinomial(\n",
    "        logits=f,\n",
    "        total_count=log_dispersions.exp()\n",
    "    ),\n",
    "    obs=torch.randint(low=0, high=100, size=(100, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029e6cd",
   "metadata": {},
   "source": [
    "# Letsa go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbae12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameshaberberger/Gitlab/gaussian-process/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1793: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"/Users/jameshaberberger/Downloads/protein_coding_raw_bulk_reduced.h5ad\")\n",
    "\n",
    "subset = adata[\n",
    "    ((adata.X.sum(axis=1) > 100000) & adata.obs[\"AgeDeath\"].gt(0) & adata.obs[\"brain_region\"].eq(\"Amygdala\")),\n",
    "]\n",
    "\n",
    "subset = subset[:, (subset.X > 0).sum(axis=0)][:, -300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56defaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/j06nrn2n7r524t776sngh0xr0000gr/T/ipykernel_95814/3328631779.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"age\": torch.tensor(subset.obs[\"AgeDeath\"], device=device).float(),\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"age\": torch.tensor(subset.obs[\"AgeDeath\"], device=device).float(),\n",
    "    \"counts\": torch.tensor(subset.X, device=device).float(),\n",
    "    \"log_exposure\": torch.tensor(subset.X.sum(axis=1) / subset.X.sum(axis=1).mean()).log(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b751293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import MultivariateNormal as MVN\n",
    "\n",
    "# --- RBF featurewise covariances ---\n",
    "def rbf_featurewise(Z, length_scales, variances, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Z: (F, Nz)\n",
    "    returns Kzz: (F, Nz, Nz)\n",
    "    \"\"\"\n",
    "    F, Nz = Z.shape\n",
    "    diffs = Z.unsqueeze(2) - Z.unsqueeze(1)            # (F,Nz,Nz)\n",
    "    D2 = diffs.pow(2)\n",
    "    ls2 = (length_scales.view(F,1,1))**2\n",
    "    var = variances.view(F,1,1)\n",
    "    Kzz = var * torch.exp(-0.5 * D2 / ls2)\n",
    "    Kzz = Kzz + jitter * torch.eye(Nz, device=Z.device).expand(F, Nz, Nz)\n",
    "    return Kzz\n",
    "\n",
    "def rbf_featurewise_cross(Z, X, length_scales, variances):\n",
    "    \"\"\"\n",
    "    Z: (F, Nz), X: (T,)\n",
    "    returns:\n",
    "      Kxz: (F, T, Nz)    covariance between X and Z\n",
    "      Kxx: (F, T, T)     covariance among X\n",
    "    \"\"\"\n",
    "    F, Nz = Z.shape\n",
    "    T = X.shape[0]\n",
    "\n",
    "    # pairwise squared distances X vs Z per feature\n",
    "    Xf = X.view(1, T, 1).expand(F, T, 1)       # (F,T,1)\n",
    "    Zf = Z.unsqueeze(1)                         # (F,1,Nz)\n",
    "    D2_xz = (Xf - Zf).pow(2)                    # (F,T,Nz)\n",
    "\n",
    "    ls2 = (length_scales.view(F,1,1))**2\n",
    "    var = variances.view(F,1,1)\n",
    "    Kxz = var * torch.exp(-0.5 * D2_xz / ls2)   # (F,T,Nz)\n",
    "\n",
    "    # Kxx uses same X for all features; only ls/var differ\n",
    "    Dx = X.view(1, T, 1) - X.view(1, 1, T)      # (1,T,T)\n",
    "    D2_xx = Dx.pow(2)\n",
    "    Kxx = variances.view(F,1,1) * torch.exp(-0.5 * D2_xx / (length_scales.view(F,1,1)**2))  # (F,T,T)\n",
    "    return Kxz, Kxx\n",
    "\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal as MVN\n",
    "\n",
    "def _cholesky_with_adaptive_jitter(K, base_jitter=1e-6, max_tries=6):\n",
    "    \"\"\"\n",
    "    K: (F, N, N)\n",
    "    returns: L (F,N,N) lower-triangular\n",
    "    \"\"\"\n",
    "    F, N, _ = K.shape\n",
    "    eye = torch.eye(N, device=K.device).expand(F, N, N)\n",
    "    jitter = torch.full((F, 1, 1), base_jitter, device=K.device)\n",
    "    for _ in range(max_tries):\n",
    "        L, info = torch.linalg.cholesky_ex(K + jitter * eye)\n",
    "        bad = info > 0\n",
    "        if not bad.any():\n",
    "            return L\n",
    "        # increase jitter only where needed\n",
    "        jitter[bad] *= 10.0\n",
    "    # last attempt: small eigenvalue floor\n",
    "    # make symmetric just in case\n",
    "    Ks = 0.5 * (K + K.transpose(-1, -2))\n",
    "    eigvals, eigvecs = torch.linalg.eigh(Ks)\n",
    "    floor = eigvals.clamp_min(base_jitter)\n",
    "    K_fixed = (eigvecs * floor.unsqueeze(-2)) @ eigvecs.transpose(-1, -2)\n",
    "    L = torch.linalg.cholesky(K_fixed + base_jitter * eye)\n",
    "    return L\n",
    "\n",
    "def gp_conditional_samples(Z, X, length_scales, variances, u=None, n_samples=1, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Z: (F, Nz)             inducing locations\n",
    "    X: (T,)                query inputs (shared across features)\n",
    "    length_scales: (F,)\n",
    "    variances: (F,)\n",
    "    u: optional (F, Nz)    inducing values; if None, sampled from MVN(0, Kzz)\n",
    "    returns:\n",
    "      f_samples: (n_samples, F, T)\n",
    "      mean: (F, T)\n",
    "      cov:  (F, T, T)\n",
    "    \"\"\"\n",
    "    # ---- shape checks\n",
    "    assert Z.dim()==2, \"Z should be (F,Nz)\"\n",
    "    assert X.dim()==1, \"X should be (T,)\"\n",
    "    F, Nz = Z.shape\n",
    "    T = X.shape[0]\n",
    "    assert length_scales.shape == (F,)\n",
    "    assert variances.shape == (F,)\n",
    "    if u is not None:\n",
    "        assert u.shape == (F, Nz)\n",
    "\n",
    "    # ---- Kzz\n",
    "    D2_zz = (Z.unsqueeze(2) - Z.unsqueeze(1)).pow(2)                 # (F,Nz,Nz)\n",
    "    ls2 = (length_scales.view(F,1,1))**2\n",
    "    var =  variances.view(F,1,1)\n",
    "    Kzz = var * torch.exp(-0.5 * D2_zz / ls2)\n",
    "    # symmetrize and factor with adaptive jitter\n",
    "    Kzz = 0.5 * (Kzz + Kzz.transpose(-1, -2))\n",
    "    Lzz = _cholesky_with_adaptive_jitter(Kzz, base_jitter=jitter)\n",
    "\n",
    "    # ---- u ~ MVN(0, Kzz) if not provided\n",
    "    if u is None:\n",
    "        zero = torch.zeros(F, Nz, device=Z.device, dtype=Z.dtype)\n",
    "        u = MVN(zero, scale_tril=Lzz).sample()                       # (F,Nz)\n",
    "\n",
    "    # ---- Kxz and Kxx\n",
    "    Xf = X.view(1, T, 1).expand(F, T, 1)                             # (F,T,1)\n",
    "    Zf = Z.unsqueeze(1)                                              # (F,1,Nz)\n",
    "    D2_xz = (Xf - Zf).pow(2)                                         # (F,T,Nz)\n",
    "    Kxz = var * torch.exp(-0.5 * D2_xz / ls2)                        # (F,T,Nz)\n",
    "    Kzx = Kxz.transpose(1, 2)                                        # (F,Nz,T)\n",
    "\n",
    "    Dx = X.view(1, T, 1) - X.view(1, 1, T)                           # (1,T,T)\n",
    "    D2_xx = Dx.pow(2)\n",
    "    Kxx = variances.view(F,1,1) * torch.exp(-0.5 * D2_xx / (length_scales.view(F,1,1)**2))  # (F,T,T)\n",
    "\n",
    "    # ---- mean = Kxz Kzz^{-1} u\n",
    "    # solve Kzz * x = u\n",
    "    x = torch.cholesky_solve(u.unsqueeze(-1), Lzz).squeeze(-1)       # (F,Nz)\n",
    "    mean = torch.matmul(Kxz, x.unsqueeze(-1)).squeeze(-1)            # (F,T)\n",
    "\n",
    "    # ---- cov = Kxx - Kxz Kzz^{-1} Kzx\n",
    "    Kzz_inv_Kzx = torch.cholesky_solve(Kzx, Lzz)                     # (F,Nz,T)\n",
    "    cov = Kxx - torch.matmul(Kxz, Kzz_inv_Kzx)                        # (F,T,T)\n",
    "    cov = 0.5 * (cov + cov.transpose(-1, -2))                        # symmetrize\n",
    "    # cholesky with adaptive jitter for the conditional covariances\n",
    "    Lxx = _cholesky_with_adaptive_jitter(cov, base_jitter=jitter)\n",
    "    # sampling via scale_tril is more stable than covariance_matrix\n",
    "    eps = torch.randn((n_samples, F, T), device=Z.device, dtype=Z.dtype)\n",
    "    f_samples = mean.unsqueeze(0) + torch.einsum('fij,sfj->sfi', Lxx, eps)\n",
    "    return f_samples, mean, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdd08558",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c655fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(dataset):\n",
    "    n_points = 10\n",
    "    n_features = dataset[\"counts\"].shape[1]\n",
    "\n",
    "    # Sample Different Inducing Points\n",
    "    inducing_points = pyro.param(\n",
    "        \"inducing_points_locations\", \n",
    "        torch.linspace(dataset[\"age\"].min(), dataset[\"age\"].max(), n_points).expand(n_features, -1).clone(),\n",
    "        constraint=dist.constraints.positive\n",
    "    )\n",
    "\n",
    "    with pyro.plate(\"inducing_points\", n_points):\n",
    "        with pyro.plate(\"features\", n_features):\n",
    "            inducing_points_loc = torch.tensor(0., device=device)\n",
    "            inducing_points_scale = torch.tensor(1., device=device)\n",
    "            inducing_point_values = pyro.sample(\n",
    "                \"inducing_point_values\",\n",
    "                dist.Normal(\n",
    "                    inducing_points_loc,\n",
    "                    inducing_points_scale\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Sample Different Kernels\n",
    "    with pyro.plate(\"kernels\", n_features):\n",
    "        # Length Scales\n",
    "        length_scale_loc = torch.tensor(1., device=device)\n",
    "        length_scale_scale = torch.tensor(1., device=device)\n",
    "        length_scales = pyro.sample(\n",
    "            \"length_scales\",\n",
    "            dist.Gamma(\n",
    "                length_scale_loc,\n",
    "                length_scale_scale\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Variances\n",
    "        variance_loc = torch.tensor(1., device=device)\n",
    "        variance_scale = torch.tensor(1., device=device)\n",
    "        variances = pyro.sample(\n",
    "            \"variances\",\n",
    "            dist.Gamma(\n",
    "                variance_loc,\n",
    "                variance_scale\n",
    "            )\n",
    "        )\n",
    "\n",
    "    with pyro.plate(\"log_dispersion\", n_features):\n",
    "        log_dispersion_loc = torch.tensor(1., device=device)\n",
    "        log_dispersion_scale = torch.tensor(1., device=device)\n",
    "        log_dispersions = pyro.sample(\n",
    "            \"log_dispersions\",\n",
    "            dist.Normal(\n",
    "                log_dispersion_loc,\n",
    "                log_dispersion_scale\n",
    "            )\n",
    "        )\n",
    "\n",
    "    f_samples, f_mean, f_cov = gp_conditional_samples(\n",
    "        inducing_points, dataset[\"age\"], length_scales, variances, u=inducing_point_values, n_samples=1, jitter=1e-6\n",
    "    )\n",
    "\n",
    "    pyro.sample(\n",
    "        \"obs\",\n",
    "        dist.NegativeBinomial(\n",
    "            logits=f_samples + dataset['log_exposure'],\n",
    "            total_count=log_dispersions.exp()\n",
    "        ),\n",
    "        obs=dataset[\"counts\"]\n",
    "    )\n",
    "\n",
    "    return f_samples, dataset['log_exposure'], log_dispersions\n",
    "\n",
    "def guide(dataset):\n",
    "    n_points   = 10\n",
    "    n_features = dataset[\"counts\"].shape[1]\n",
    "    device     = dataset[\"counts\"].device\n",
    "    dtype      = dataset[\"counts\"].dtype\n",
    "\n",
    "    # --- Inducing point locations: optimized parameter (same name as in model) ---\n",
    "    _ = pyro.param(\n",
    "        \"inducing_points_locations\",\n",
    "        torch.linspace(dataset[\"age\"].min(), dataset[\"age\"].max(), n_points, device=device, dtype=dtype)\n",
    "             .expand(n_features, -1).clone(),\n",
    "        constraint=dist.constraints.positive\n",
    "    )\n",
    "\n",
    "    # --- Variational for inducing_point_values (matches model plates) ---\n",
    "    with pyro.plate(\"inducing_points\", n_points):\n",
    "        with pyro.plate(\"features\", n_features):\n",
    "            loc = pyro.param(\n",
    "                \"inducing_point_values_loc\",\n",
    "                torch.zeros(n_features, n_points, device=device, dtype=dtype)\n",
    "            )\n",
    "            # start small to avoid early blow-ups; softplus -> positive\n",
    "            scale_u = pyro.param(\n",
    "                \"inducing_point_values_scale_unconstrained\",\n",
    "                torch.full((n_features, n_points), -2.0, device=device, dtype=dtype)\n",
    "            )\n",
    "            scale = F.softplus(scale_u) + 1e-6\n",
    "            pyro.sample(\"inducing_point_values\", dist.Normal(loc, scale))\n",
    "\n",
    "    # --- Variational for kernel hyperparams (positive via softplus+eps) ---\n",
    "    with pyro.plate(\"kernels\", n_features):\n",
    "        ls_alpha_u = pyro.param(\"length_scale_alpha_unconstrained\",\n",
    "                                torch.zeros(n_features, device=device, dtype=dtype))\n",
    "        ls_beta_u  = pyro.param(\"length_scale_beta_unconstrained\",\n",
    "                                torch.zeros(n_features, device=device, dtype=dtype))\n",
    "        ls_alpha = F.softplus(ls_alpha_u) + 1e-6\n",
    "        ls_beta  = F.softplus(ls_beta_u)  + 1e-6\n",
    "        pyro.sample(\"length_scales\", dist.Gamma(ls_alpha, ls_beta))\n",
    "\n",
    "        var_alpha_u = pyro.param(\"variance_alpha_unconstrained\",\n",
    "                                 torch.zeros(n_features, device=device, dtype=dtype))\n",
    "        var_beta_u  = pyro.param(\"variance_beta_unconstrained\",\n",
    "                                 torch.zeros(n_features, device=device, dtype=dtype))\n",
    "        var_alpha = F.softplus(var_alpha_u) + 1e-6\n",
    "        var_beta  = F.softplus(var_beta_u)  + 1e-6\n",
    "        pyro.sample(\"variances\", dist.Gamma(var_alpha, var_beta))\n",
    "\n",
    "    with pyro.plate(\"log_dispersion\", n_features):\n",
    "        # Variational Normal guide for log-dispersions\n",
    "        log_dispersion_mean = pyro.param(\n",
    "            \"log_dispersion_mean\",\n",
    "            torch.zeros(n_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        log_dispersion_std = pyro.param(\n",
    "            \"log_dispersion_std\",\n",
    "            0.1 * torch.ones(n_features, device=device, dtype=dtype),\n",
    "            constraint=dist.constraints.positive\n",
    "        )\n",
    "\n",
    "        pyro.sample(\"log_dispersions\", dist.Normal(log_dispersion_mean, log_dispersion_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63aa86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_samples, log_exposure, log_dispersion = model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "004f31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameshaberberger/Gitlab/gaussian-process/.venv/lib/python3.13/site-packages/pyro/primitives.py:163: RuntimeWarning: trying to observe a value outside of inference at obs\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 300])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample(\n",
    "    \"obs\",\n",
    "    dist.NegativeBinomial(\n",
    "        logits=f_samples + dataset['log_exposure'],\n",
    "        total_count=log_dispersions.exp()\n",
    "    ),\n",
    "    obs=dataset[\"counts\"]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e3ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/Users/jameshaberberger/Gitlab/gaussian-process/.venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:220: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  grads = [p.grad for p in parameters if p.grad is not None]\n",
      "/Users/jameshaberberger/Gitlab/gaussian-process/.venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:147: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  grads = [p.grad for p in parameters if p.grad is not None]\n",
      " 90%|████████▉ | 8992/10000 [01:00<00:06, 155.13it/s, ELBO=1.2062]   "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pyro\n",
    "import pyro.optim as optim\n",
    "import pyro.infer as infer\n",
    "\n",
    "# --- Setup optimizer and ELBO ---\n",
    "optimizer = optim.Adam({\"lr\": 1e-3})\n",
    "elbo = infer.Trace_ELBO()\n",
    "svi = infer.SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# --- Training loop with tqdm ---\n",
    "def train_svi(dataset, num_steps=2000):\n",
    "    pyro.clear_param_store()\n",
    "    losses = []\n",
    "\n",
    "    with tqdm(range(num_steps)) as pbar:\n",
    "        for step in pbar:\n",
    "            loss = svi.step(dataset)\n",
    "            losses.append(loss)\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(pyro.get_param_store().values()), \n",
    "                max_norm=10.0\n",
    "            )\n",
    "\n",
    "            # update postfix on tqdm bar\n",
    "            pbar.set_postfix({\"ELBO\": f\"{loss:.4f}\"})\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Example usage\n",
    "losses = train_svi(dataset, num_steps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "303cb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16a02ee90>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPw5JREFUeJzt3Qd4VFX6x/E3PRBIQoAklISiSC9SpAgokiUUURRUFIFVFiygAi4KK2AXF6wogmVd2BUXZVdQQZpUhdClQwBBCGASICQhgfT5P+f4nzGDkwYzd9r38zzjZO45M/PmJmR+3nvOuT4mk8kkAAAAbsTX2QUAAABUFAEGAAC4HQIMAABwOwQYAADgdggwAADA7RBgAACA2yHAAAAAt0OAAQAAbsdfPFRRUZGcOXNGqlatKj4+Ps4uBwAAlINaX/fixYtSu3Zt8fX19b4Ao8JLTEyMs8sAAABXISkpSerWret9AUYdeTHvgNDQUGeXAwAAyiEzM1MfgDB/jntdgDGfNlLhhQADAIB7KWv4B4N4AQCA2yHAAAAAt0OAAQAAbocAAwAA3A4BBgAAuB0CDAAAcDsEGAAA4HYIMAAAwO0QYAAAgNshwAAAALdDgAEAAG6HAAMAADw/wGzYsEH69+8vtWvX1hdaWrx48R/6HDx4UO644w4JCwuTkJAQ6dChg5w8edLSnpOTI6NHj5bq1atLlSpVZODAgZKSkmL1Gqp/v379pHLlyhIZGSkTJkyQgoICcbbLeYUyffkh+W7vr84uBQAAr1XhAJOdnS2tW7eWWbNm2Wz/+eefpWvXrtKkSRNZt26d7NmzR6ZMmSLBwcGWPuPGjZNvv/1WFi5cKOvXr5czZ87I3XffbWkvLCzU4SUvL082bdok8+bNk7lz58rUqVPF2d7+/rB8sO5neXz+Ttl3OsPZ5QAA4JV8TCaT6aqf7OMjixYtkgEDBli2DR48WAICAuTf//63zedkZGRIzZo15fPPP5dBgwbpbYcOHZKmTZtKQkKCdOrUSZYtWya33367DjZRUVG6z5w5c+TZZ5+Vs2fPSmBgYJm1ZWZm6iNA6v1CQ0PFXu76YKP8dDJdf/1M78by+K3X2+21AQDwdpnl/Py26xiYoqIiWbp0qdxwww0SHx+vT/107NjR6jTTjh07JD8/X+Li4izb1NGa2NhYHWAUdd+yZUtLeFHU66lvav/+/TbfOzc3V7cXvzmCr4+P5evpyxOlsOiq8x8AALhKdg0wqampkpWVJa+//rr07t1bVq5cKXfddZc+PaROFSnJycn6CEp4eLjVc1VYUW3mPsXDi7nd3GbLtGnTdGIz32JiYuz5rVn4FQswyrurjzjkfQAAgBh3BEa588479TiXNm3ayMSJE/XpIHUKyJEmTZqkDzeZb0lJSQ55n62/pFk9Pn3hskPeBwAAGBRgatSoIf7+/tKsWTOr7Wp8i3kWUnR0tB6cm57+2zgSMzULSbWZ+1w5K8n82NznSkFBQfpcWfGbEXytD8gAAAB3CzDq1JCaMp2YmGi1/fDhw1KvXj39dbt27fQg39WrV1vaVX8VcDp37qwfq/u9e/fqU1Jmq1at0qHkynDkbMXHxAAAAGP4V/QJaozL0aNHLY+PHz8uu3btkoiICD0QV63Xct9990n37t2lR48esnz5cj1lWk2pVtT4lBEjRsj48eP1c1QoeeKJJ3RoUTOQlF69eumgMnToUJk+fboe9zJ58mS9dow60uJKfDkEAwCA60+jVkFEBZMrDR8+XK/Vonz66ad6UO2pU6ekcePG8uKLL+pxMcUXsnv66aflP//5j549pGYYffDBB1anh06cOCGPPfaYfj+1GJ56fTU4WJ2iKg9HTaOuP3Gp1eMqQf6y78V4u70+AADeLLOcn9/XtA6MKzMqwCj/GdlJOl9X3W7vAQCAt8p0xjow3ur+jzfLmXRmIwEAYBQCjJ1M/Xqfs0sAAMBrEGDsJC07z9klAADgNQgwdsIlBQAAMA4BpoJCAv1sbt99iitTAwBgFAJMBfVvXdvZJQAA4PUIMBU0tb9rrQQMAIA3IsBUUOVAf9n6XE9nlwEAgFcjwFyFyKrBzi4BAACvRoCxI2YiAQBgDAKMHeXkFzq7BAAAvAIBxo4e+uc2WZuY6uwyAADweAQYO9r6S5oOMQAAwLEIMAAAwO0QYAAAgNshwAAAALdDgLlKcx/q4OwSAADwWgSYq3Rr48gS2zYdPWdoLQAAeBsCzDUY1b2hze0PfLJFLmTnGV4PAADeggBzDf7Wt2mJbe+uPmJoLQAAeBMCjINczClwdgkAAHgsAoyD/G/nKWeXAACAxyLAAAAAt0OAAQAAbocA40Amk8nZJQAA4JEIMA6048QFZ5cAAIBHIsA40KA5CXIuK9fZZQAA4HEIMHYS6G97Vy7b+6vhtQAA4OkIMA425ev9kpXLmjAAANgTAeYazRjUSgL9fOWTYe1L7DPxf3sMrQkAAE9HgLlG97SPkYMv95buN9Qssc+SPZxGAgDAqQFmw4YN0r9/f6ldu7b4+PjI4sWLS+z76KOP6j7vvPOO1fa0tDQZMmSIhIaGSnh4uIwYMUKysrKs+uzZs0e6desmwcHBEhMTI9OnTxdX5efr4+wSAADwKhUOMNnZ2dK6dWuZNWtWqf0WLVokmzdv1kHnSiq87N+/X1atWiVLlizRoWjUqFGW9szMTOnVq5fUq1dPduzYITNmzJAXXnhBPvroI3FX55mNBACA3fhX9Al9+vTRt9KcPn1annjiCVmxYoX069fPqu3gwYOyfPly2bZtm7Rv/9u4kffee0/69u0rb7zxhg488+fPl7y8PPn0008lMDBQmjdvLrt27ZK33nrLKui4kwf/sVWWPdXN2WUAAOAR7D4GpqioSIYOHSoTJkzQweNKCQkJ+rSRObwocXFx4uvrK1u2bLH06d69uw4vZvHx8ZKYmCgXLtheHC43N1cfuSl+cyUHf3WtegAAcGd2DzB///vfxd/fX5588kmb7cnJyRIZGWm1TfWPiIjQbeY+UVFRVn3Mj819rjRt2jQJCwuz3NS4GQAA4JnsGmDUeJV3331X5s6dqwfvGmnSpEmSkZFhuSUlJRn6/gAAwDh2DTA//PCDpKamSmxsrD6qom4nTpyQp59+WurXr6/7REdH6z7FFRQU6JlJqs3cJyUlxaqP+bG5z5WCgoL0rKbiN6MNbFvX8PcEAMAb2TXAqLEvavqzGnBrvqlBuWo8jBrQq3Tu3FnS09P10RqzNWvW6LEzHTt2tPRRM5Py8/MtfdSMpcaNG0u1atXEVU3q28TZJQAA4BUqPAtJrddy9OhRy+Pjx4/roKLGsKgjL9WrV7fqHxAQoI+aqPChNG3aVHr37i0jR46UOXPm6JAyZswYGTx4sGXK9QMPPCAvvviiXh/m2WeflX379ulTU2+//ba4suohgdImJlx2JaU7uxQAADxahY/AbN++XW688UZ9U8aPH6+/njp1arlfQ02TbtKkifTs2VNPn+7atavVGi9qEO7KlSt1OGrXrp0+BaVe39WnUKtxP4se7+LsMgAA8Hg+JpPJJB5ITaNWQUgN6DV6PEz9iUttbj8+ra/hg5sBAPDEz2+uhWSgN1cednYJAAB4BAKMAzSrZTsxvr/2qJy6cMnwegAA8DQEGIN1/fta+f6A9RRxAABQMQQYByhrmMtf/rXdqFIAAPBIBBgHePPe1s4uAQAAj0aAcYAm0aGyc8qf5LW7Wjq7FAAAPBIBxkEiQgLl7rZ1nF0GAAAeiQDjQP6+JQ+Gybj0+2USAABAxRBgHMivlADz8tIDhtYCAIAnIcA4UGmr7h5KzjS0FgAAPAkBxsHGxjWyub2wyPBSAADwGAQYBxvYtq6zSwAAwOMQYBwsJqKyze0Hf+UUEgAAV4sA40TTvjvo7BIAAHBLBBgn+nDDMWeXAACAWyLAAAAAt0OAAQAAbocAY4A64ZWcXQIAAB6FAGOAKbc3c3YJAAB4FAKMAXq3iHZ2CQAAeBQCDAAAcDsEGAAA4HYIME72MWvBAABQYQQYJ3uV1XgBAKgwAgwAAHA7BBgAAOB2CDAGWfpkV2eXAACAxyDAGKR57TC5+8Y6NtsyLucbXg8AAO6MAGOgN+9tbXN76xdXysUcQgwAAOVFgDGQj4+PbJp4m822ez/cbHg9AAB4TYDZsGGD9O/fX2rXrq0/kBcvXmxpy8/Pl2effVZatmwpISEhus+wYcPkzJkzVq+RlpYmQ4YMkdDQUAkPD5cRI0ZIVlaWVZ89e/ZIt27dJDg4WGJiYmT69OniCWqXcGHHg79mGl4LAABeE2Cys7OldevWMmvWrD+0Xbp0SXbu3ClTpkzR91999ZUkJibKHXfcYdVPhZf9+/fLqlWrZMmSJToUjRo1ytKemZkpvXr1knr16smOHTtkxowZ8sILL8hHH30knuzYWesQBwAAbPMxmUwmuUrqCMyiRYtkwIABJfbZtm2b3HTTTXLixAmJjY2VgwcPSrNmzfT29u3b6z7Lly+Xvn37yqlTp/RRm9mzZ8tzzz0nycnJEhgYqPtMnDhRH+05dOhQuWpTISgsLEwyMjL0kR5XUn/iUpvbG9YMkTVP32p4PQAAuIryfn47fAyMKkAFHXWqSElISNBfm8OLEhcXJ76+vrJlyxZLn+7du1vCixIfH6+P5ly4cMHm++Tm5upvuvjNVe2c8ieb24+dzZYL2XmG1wMAgLtxaIDJycnRY2Luv/9+S4pSR1UiIyOt+vn7+0tERIRuM/eJioqy6mN+bO5zpWnTpunEZr6pcTOuKiLk92B2pekryneECQAAb+awAKMG9N57772izlCpU0KONmnSJH20x3xLSkoSV/bOfW1sbt/+i+0jTAAA4Hf+4sDwosa9rFmzxuocVnR0tKSmplr1Lygo0DOTVJu5T0pKilUf82NznysFBQXpm7vw8bG9/UgqA3kBADD8CIw5vBw5ckS+//57qV69ulV7586dJT09Xc8uMlMhp6ioSDp27Gjpo2YmqdcyUzOWGjduLNWqVbN3yQAAwNMDjFqvZdeuXfqmHD9+XH998uRJHTgGDRok27dvl/nz50thYaEes6JueXm/DU5t2rSp9O7dW0aOHClbt26VjRs3ypgxY2Tw4MF6BpLywAMP6AG8an0YNd36iy++kHfffVfGjx8v3uCDdUedXQIAAJ41jXrdunXSo0ePP2wfPny4XqulQYMGNp+3du1aufXW36YIq9NFKrR8++23evbRwIEDZebMmVKlShWrhexGjx6tp1vXqFFDnnjiCT0guLxceRq1ci4rV9q/8n2J7cde6yu+viWcZwIAwEOV9/P7mtaBcWWuHmCUA2cype/MH2y2HX21j/j7caUHAIB3yXSVdWBQssjQkgcdX8wpMLQWAADcCQHGiUo7QfT0wt0GVgIAgHshwLjognZrDllPNQcAAL8jwDiRusRCaYqKPHJ4EgAA14wA48L+t/OUs0sAAMAlEWCcbN7DN5XYxqq8AADYRoBxsltuqFli27pExsEAAGALAcYFPHRzfZvbD6dwBAYAAFsIMC7g+f7NnV0CAABuhQDjIhaM6mRze2LyRcNrAQDA1RFgXERJE6rj39lgcCUAALg+AoybrAkDAAB+R4ABAABuhwDjIjgAAwBA+RFgXETLOmEltr269IChtQAA4OoIMC4iOMCvxLaPfzguyRk5htYDAIArI8C4ifzCImeXAACAyyDAuAkTF6YGAMCCAONC/vtoZ2eXAACAWyDAuJD29SOkTnglZ5cBAIDLI8C4mNBKAc4uAQAAl0eAcTED29axud0kDIIBAMCMAONihnepb3P7LTPWyW1vrpOLOfmG1wQAgKshwLiYAD9f+UvXBjbbjp3NlpYvrDS8JgAAXA0BxgU93auxs0sAAMClEWBcUKXAklflBQAABBiX9e7gNiW25RWwKi8AwLsRYFzUnW1sz0ZSth5PM7QWAABcDQHGDTGlGgDg7QgwbujsxVxnlwAAgFMRYNzQ+C93O7sEAADcK8Bs2LBB+vfvL7Vr1xYfHx9ZvHixVbvJZJKpU6dKrVq1pFKlShIXFydHjhyx6pOWliZDhgyR0NBQCQ8PlxEjRkhWVpZVnz179ki3bt0kODhYYmJiZPr06eJtKgWUPBspKe2SobUAAODWASY7O1tat24ts2bNstmugsbMmTNlzpw5smXLFgkJCZH4+HjJycmx9FHhZf/+/bJq1SpZsmSJDkWjRo2ytGdmZkqvXr2kXr16smPHDpkxY4a88MIL8tFHH4k3ubd93RLbFu44ZWgtAAC4Ev+KPqFPnz76Zos6+vLOO+/I5MmT5c4779Tb/vWvf0lUVJQ+UjN48GA5ePCgLF++XLZt2ybt27fXfd577z3p27evvPHGG/rIzvz58yUvL08+/fRTCQwMlObNm8uuXbvkrbfesgo63izzMpcUAAB4L7uOgTl+/LgkJyfr00ZmYWFh0rFjR0lISNCP1b06bWQOL4rq7+vrq4/YmPt0795dhxczdRQnMTFRLly4YPO9c3Nz9ZGb4jdPNnfTL6wHAwDwWnYNMCq8KOqIS3HqsblN3UdGRlq1+/v7S0REhFUfW69R/D2uNG3aNB2WzDc1bsbTffLjMWeXAACAU3jMLKRJkyZJRkaG5ZaUlCSeLintsrNLAADA/QNMdHS0vk9JSbHarh6b29R9amqqVXtBQYGemVS8j63XKP4eVwoKCtKzmorf3F3rmPAyerCgHQDAO9k1wDRo0EAHjNWrV1u2qbEoamxL586d9WN1n56ermcXma1Zs0aKior0WBlzHzUzKT//94GqasZS48aNpVq1auItBrSpI9MHtSqx3UR+AQB4qQoHGLVei5oRpG7mgbvq65MnT+p1YcaOHSuvvPKKfPPNN7J3714ZNmyYnlk0YMAA3b9p06bSu3dvGTlypGzdulU2btwoY8aM0TOUVD/lgQce0AN41fowarr1F198Ie+++66MHz9evImvr4/c2z5GFj76W/i70oJtnn+aDAAAu0yj3r59u/To0cPy2Bwqhg8fLnPnzpVnnnlGrxWjpjurIy1du3bV06bVgnRmapq0Ci09e/bUs48GDhyo144xU4NwV65cKaNHj5Z27dpJjRo19OJ43jqFukP9iBLbtv+SJu1LaQcAwBP5mNTiLR5InbpSQUgN6PWE8TD1Jy61uf3lAS1kaKd6htcDAIAzP789ZhaSp4usGmRze1GRR+ZPAABKRYBxE4tG32xz++X8QsNrAQDA2QgwbqJOeCWb219fdkhyCwgxAADvQoBxI1WDbI+5nrBwj+G1AADgTAQYN/Lvv/y2Ts6Vvtl9xvBaAABwJgKMG2lT5sq8AAB4BwKMh5iyeJ9cyM5zdhkAABiCAOMh/r35hDw2//fLMwAA4MkIMB5k87E0Z5cAAIAhCDBuZvXTtzi7BAAAnI4A42auq1lFVo7r7uwyAABwKgKMG7ohqqqzSwAAwKkIMAAAwO0QYAAAgNshwLipJtG2TyNxdWoAgDcgwLipf/y5g83t936YYHgtAAAYjQDjxlenfrBT7B+2bz9xQepPXCrZuQVOqQsAACMQYNxYbETlEtveW3PU0FoAADASAcaN+fr4lNiWdOGSobUAAGAkAowbq1c9xNklAADgFAQYNxbXNLLEtuSMHENrAQDASAQYN+ZTyimkHScuSEomIQYA4JkIMG6uRpWgEtvu/3izobUAAGAUAoybm/uQ7fVglGNnsw2tBQAAoxBg3FyLOmGltucWFBpWCwAARiHAeLj+7/3o7BIAALA7AoyHO5yS5ewSAACwOwKMFzCZuMAjAMCzEGC8wLFzDOYFAHgWAowXOJN+2dklAADg2gGmsLBQpkyZIg0aNJBKlSrJddddJy+//LLVaQz19dSpU6VWrVq6T1xcnBw5csTqddLS0mTIkCESGhoq4eHhMmLECMnKYjzH1fjrwt3OLgEAANcOMH//+99l9uzZ8v7778vBgwf14+nTp8t7771n6aMez5w5U+bMmSNbtmyRkJAQiY+Pl5yc31eOVeFl//79smrVKlmyZIls2LBBRo0aZe9yPUpkVduL2qVk5hpeCwAAbhVgNm3aJHfeeaf069dP6tevL4MGDZJevXrJ1q1bLUdf3nnnHZk8ebLu16pVK/nXv/4lZ86ckcWLF+s+KvgsX75cPvnkE+nYsaN07dpVB6AFCxbofrDt3vYxzi4BAAD3DDBdunSR1atXy+HDh/Xj3bt3y48//ih9+vTRj48fPy7Jycn6tJFZWFiYDioJCQn6sbpXp43at29v6aP6+/r66iM2tuTm5kpmZqbVzVssGNVJRnZrIGNuu97ZpQAAYAh/e7/gxIkTdXho0qSJ+Pn56TExr776qj4lpKjwokRFRVk9Tz02t6n7yEjrKy37+/tLRESEpc+Vpk2bJi+++KJ4o04Nq+sbAADewu5HYL788kuZP3++fP7557Jz506ZN2+evPHGG/rekSZNmiQZGRmWW1JSknijr0ffbHP7jhNphtcCAIDbBJgJEyboozCDBw+Wli1bytChQ2XcuHH6CIkSHR2t71NSUqyepx6b29R9amqqVXtBQYGemWTuc6WgoCA9Y6n4zRu1jgm3uX3g7AQ5lOw9p9UAAJ7N7gHm0qVLeqxKcepUUlFRkf5aTa9WIUSNkzFTp5zU2JbOnTvrx+o+PT1dduzYYemzZs0a/RpqrAyuzl/mbXd2CQAAuOYYmP79++sxL7GxsdK8eXP56aef5K233pKHH35Yt/v4+MjYsWPllVdekUaNGulAo9aNqV27tgwYMED3adq0qfTu3VtGjhypp1rn5+fLmDFj9FEd1Q9X59SFy1JYZBI/Xx9nlwIAgGsFGDXdWQWSxx9/XJ8GUoHjkUce0QvXmT3zzDOSnZ2t13VRR1rUNGk1bTo4ONjSR42jUaGlZ8+e+ojOwIED9doxuDafbz0pQzvVc3YZAABcEx+Th17pT52WUtOz1YBebxsP0/KFFXIxp6DE9l9e72doPQAA2Pvzm2sheaCGNUKcXQIAAA5FgPFAlQL9nF0CAAAORYDxQNPubiWNo6o6uwwAAByGAOOBGtQIkRXjuktsRGWb7Q98vNnwmgAAsCcCjAdrWNP2WJhNP583vBYAAOyJAOPBWO0FAOCpCDAezNen5AiTlVvyNGsAAFwdAcaD3dO+bolt+05nGFoLAAD2RIDxYLc2jiyxbfBHmyUp7ZKh9QAAYC8EGC89haR0m75W1h8+a1g9AADYCwHGg5WRX7T5m08YUQoAAHZFgPFgAX78eAEAnolPOA931411Sm2/nF9oWC0AANiLv91eCS7ppTuby42x4dImJlzueH/jH9p/OHJOcvILJTiA6ycBANwHR2A8XNXgABnWub60qhteYp83VyYaWhMAANeKAANZfSjV2SUAAFAhBBhwyQEAgNshwEB8yjPfGgAAF0KAgRxNzZIdJ9KcXQYAAOVGgPEiMwa1KrFt4OwEQ2sBAOBaEGC8yD3tY+T+m2JLbE/JzDG0HgAArhYBxstM7N2kxLa7P9hkaC0AAFwtAoyXCascUGLb6fTLhtYCAMDVIsB4oZcHtCix7XxWrqG1AABwNQgwXqhGSGCJbe1e+d7QWgAAuBoEGC/Eui8AAHdHgPFC5BcAgLsjwHgh3zISzF0fbJT0S3mG1QMAQEURYLxQWQdgfjqZLrPWHjWoGgAAKo4A44WqhZQ8ldps63EuLQAAcF0EGC/UNraaPHJLw1L77D6VYVg9AAC4RIA5ffq0PPjgg1K9enWpVKmStGzZUrZv325pN5lMMnXqVKlVq5Zuj4uLkyNHjli9RlpamgwZMkRCQ0MlPDxcRowYIVlZWY4o1ytnIU3q09TZZQAA4DoB5sKFC3LzzTdLQECALFu2TA4cOCBvvvmmVKtWzdJn+vTpMnPmTJkzZ45s2bJFQkJCJD4+XnJyfr8Wjwov+/fvl1WrVsmSJUtkw4YNMmrUKHuX69Xim0c5uwQAAK6Kj0kdDrGjiRMnysaNG+WHH36w2a7ernbt2vL000/LX//6V70tIyNDoqKiZO7cuTJ48GA5ePCgNGvWTLZt2ybt27fXfZYvXy59+/aVU6dO6eeXJTMzU8LCwvRrq6M4+KPs3AL5/mCKPLVgl832VeO6y6Of7ZAnbmskA26sY3h9AADvk1nOz2+7H4H55ptvdOi45557JDIyUm688Ub5+OOPLe3Hjx+X5ORkfdrITBXasWNHSUhI0I/VvTptZA4viurv6+urj9jYkpubq7/p4jeULiTIX+5sU0fuaVfXZvuf3t4gP5/NlrFf2A44AAA4i90DzLFjx2T27NnSqFEjWbFihTz22GPy5JNPyrx583S7Ci+KOuJSnHpsblP3KvwU5+/vLxEREZY+V5o2bZoOQuZbTEyMvb81jzXjntbOLgEAAOcGmKKiImnbtq289tpr+uiLGrcycuRIPd7FkSZNmqQPN5lvSUlJDn0/AADgQQFGzSxS41eKa9q0qZw8eVJ/HR0dre9TUlKs+qjH5jZ1n5qaatVeUFCgZyaZ+1wpKChInysrfgMAAJ7J7gFGzUBKTEy02nb48GGpV6+e/rpBgwY6hKxevdrSrsarqLEtnTt31o/VfXp6uuzYscPSZ82aNfrojhorAwAAvJu/vV9w3Lhx0qVLF30K6d5775WtW7fKRx99pG/mNUjGjh0rr7zyih4nowLNlClT9MyiAQMGWI7Y9O7d23LqKT8/X8aMGaNnKJVnBhIAAPBsdg8wHTp0kEWLFukxKS+99JIOKO+8845e18XsmWeekezsbD0+Rh1p6dq1q54mHRwcbOkzf/58HVp69uypZx8NHDhQrx0Dx+jUMEI2H+PyAQAAL10HxlWwDkzFnMvKlfavfF9i+74X46VKkN3zLgAArrEODNxTjSpBcl3NkBLb+75re2FCAACcgQADizfvbVNi28m0S4bWAgBAaQgwsGgTE15qe1GRR55tBAC4IQIMym3QnE3OLgEAAI0Ag3LbeTLd2SUAAKARYAAAgNshwAAAALdDgEGF/Hw2y9klAABAgIG1r0ffXGp7zzfXy4XsPMPqAQDAFpZWhZXWMeGy9bmesuHwOfk1/bK8ueqwzTVhqoUEOqU+AAAUjsDgDyKrBsugdnUlKMD2r8elvELDawIAoDgCDErkIz42t9//8WbDawEAoDgCDEp0V9s6JbZl5xYYWgsAAMURYFDqBR5L0vz5FZJ6McfQegAAMCPA4KqtOpDi7BIAAF6KAINSvXZXyxLbzl1kOjUAwDkIMCiVv5/tgbzK29//cYo1AABGIMDgmvxn60lnlwAA8EIEGJQqvnl0qe2TvtprWC0AAJgRYFCqsEoBMrrHdaX2YTYSAMBoBBiUKcCv9F+Tm15dbVgtAAAoBBhc9Yq8xZ29mGtILQAAKAQY2MXOkxecXQIAwIsQYFAmn7IPwMjupHQjSgEAQCPAoEzlyC/ywbqfDagEAIDfEGBQpjax4eXq1/G17x1eCwAACgEGZerWqKbMebBdmf1SMhnICwAwBgEG5dK7RekL2pklpV1yeC0AABBgUG5t//9UUpPoqvLTlD/Z7NNt+lqDqwIAeCN/ZxcA9/Hh0PayYOtJubdDjFQLCSyx308nL8iNsdUMrQ0A4F0cfgTm9ddfFx8fHxk7dqxlW05OjowePVqqV68uVapUkYEDB0pKSorV806ePCn9+vWTypUrS2RkpEyYMEEKCgocXS5KUbNqkDzRs5FEhQaX2u+uDzYZVhMAwDs5NMBs27ZNPvzwQ2nVqpXV9nHjxsm3334rCxculPXr18uZM2fk7rvvtrQXFhbq8JKXlyebNm2SefPmydy5c2Xq1KmOLBcAAHh7gMnKypIhQ4bIxx9/LNWq/X46ISMjQ/7xj3/IW2+9Jbfddpu0a9dO/vnPf+qgsnnzZt1n5cqVcuDAAfnss8+kTZs20qdPH3n55Zdl1qxZOtTA9W08ek72nGJxOwCAmwUYdYpIHUWJi4uz2r5jxw7Jz8+32t6kSROJjY2VhIQE/Vjdt2zZUqKioix94uPjJTMzU/bv32/z/XJzc3V78RucZ8gnW+SO9zc6uwwAgIdyyCDeBQsWyM6dO/UppCslJydLYGCghIdbL46mwopqM/cpHl7M7eY2W6ZNmyYvvviiHb8LAADgNUdgkpKS5KmnnpL58+dLcHDpgz3tadKkSfr0lPmm6oDzpV/ilB8AwA0CjDpFlJqaKm3bthV/f399UwN1Z86cqb9WR1LUOJb0dOvxEWoWUnT0b4ulqfsrZyWZH5v7XCkoKEhCQ0OtbnCsOQ+2lQnxjUvt0+X1NYbVAwDwHnYPMD179pS9e/fKrl27LLf27dvrAb3mrwMCAmT16tWW5yQmJupp0507d9aP1b16DRWEzFatWqVDSbNmzexdMq5S7xa1ZHSP6yU0uOQzkZfyCg2tCQDgHew+BqZq1arSokULq20hISF6zRfz9hEjRsj48eMlIiJCh5InnnhCh5ZOnTrp9l69eumgMnToUJk+fboe9zJ58mQ9MFgdaYFr6X5DTVmy59cS200mk14LCAAAt76UwNtvvy233367XsCue/fu+rTQV199ZWn38/OTJUuW6HsVbB588EEZNmyYvPTSS84oF2UY2K5uqe3tXuEq1QAA+/Ixqf899kBqGnVYWJge0Mt4GMfafOy8DP7otzV8SqLGyjzSvaH4+3H5LQDAtX9+82mCa3Z9ZJUy+8xYkSiPzd9pSD0AAM9HgME1q1ElSNb99dYy+606YD2zDACAq0WAgV3UrxHi7BIAAF6EAAO7aRJdtcw+93+0WU6ev2RIPQAAz0WAgd3M/0vHMvskHDsv47/cZUg9AADPRYCB3VSvEiTHXutbZr/kzBxD6gEAeC4CDOzK19dHqgSVvj7iqQuXDasHAOCZCDCwu+431CizD+NgAADXggADu5t2V6sy+xxOuWhILQAAz0SAgd2FVQ4os8+4L3fJpqPnDKkHAOB5CDBwios5BfLAJ1ucXQYAwE0RYAAAgNshwAAAALdDgIFD3FQ/wtklAAA8GAEGDjH34Q7y0dB2MrrHdaX2qz9xqWw4fFYKi0yG1QYAcH8EGDhE5UB/6dU8WsbF3VBm32GfbpV3vz9sSF0AAM9AgIFD+fuV71dszoZjkp1b4PB6AACegQADh/vuyW5SrYy1YfIKiqT58yvklSUHDKsLAOC+CDBwuGa1Q+Wnqb1k1gNty+z7yY/HDakJAODeCDAwTL9WtcrVb+bqIw6vBQDg3ggwcDlvrTosJ85nO7sMAIALI8DAUN+Pv6XclxoAAKAkBBgYysenfP1+Ppvl6FIAAG6MAAOX9NSCXXpmEgAAthBgYKjYiMrl7nspj9NIAADbCDAwVICfrxx+pY8cfbWPfPrn9qX2/fM/t0nGpXzDagMAuA8CDAwX6O+rV+jt0Tiy1H67ktJl6jf7DKsLAOA+CDBwGp9yjOj9etcZQ2oBALgXAgxcXmLyRWeXAABwMQQYuLxJX+0Rk8nk7DIAAC6EAAOnqhzoV2afnSfTpcGk7yT+7Q0M6gUAOCbATJs2TTp06CBVq1aVyMhIGTBggCQmJlr1ycnJkdGjR0v16tWlSpUqMnDgQElJSbHqc/LkSenXr59UrlxZv86ECROkoIBptZ5m5bju8vKAFtKxQUSZfRNTLsonPx4zpC4AgJcFmPXr1+twsnnzZlm1apXk5+dLr169JDv792vbjBs3Tr799ltZuHCh7n/mzBm5++67Le2FhYU6vOTl5cmmTZtk3rx5MnfuXJk6daq9y4WT1a1WWYZ2qid33VinXP3zClncDgAg4mNy8OCCs2fP6iMoKqh0795dMjIypGbNmvL555/LoEGDdJ9Dhw5J06ZNJSEhQTp16iTLli2T22+/XQebqKgo3WfOnDny7LPP6tcLDAws830zMzMlLCxMv19oaKgjv0XYQUFhkVz/3LIy+/VpES2zH2xnSE0AAOOV9/Pb4WNgVAFKRMRvpwh27Nihj8rExcVZ+jRp0kRiY2N1gFHUfcuWLS3hRYmPj9ff1P79+22+T25urm4vfoP7UOvC/PJ6P/lzl/ql9lu2L1n+8eNxw+oCALgmhwaYoqIiGTt2rNx8883SokULvS05OVkfQQkPD7fqq8KKajP3KR5ezO3mtpLG3qjEZr7FxMQ46LuCI71wR/My+7y85IDUn7hUdpxIM6QmAICXBRg1Fmbfvn2yYMECcbRJkybpoz3mW1JSksPfE841cHaCZOcysBsAvJHDAsyYMWNkyZIlsnbtWqlbt65le3R0tB6cm56ebtVfzUJSbeY+V85KMj8297lSUFCQPldW/AbP1/z5FXL83O8DxAEA3sHuAUaNCVbhZdGiRbJmzRpp0KCBVXu7du0kICBAVq9ebdmmplmradOdO3fWj9X93r17JTU11dJHzWhSoaRZs2b2Lhlurscb61gfBgC8jK8jTht99tlnepaRWgtGjVlRt8uXL+t2NT5lxIgRMn78eH10Rg3qfeihh3RoUTOQFDXtWgWVoUOHyu7du2XFihUyefJk/drqSAtwpb8t3uvsEgAA7hxgZs+erceg3HrrrVKrVi3L7YsvvrD0efvtt/U0abWAnZparU4LffXVV5Z2Pz8/ffpJ3atg8+CDD8qwYcPkpZdesne5cEHlWdTuSkv3/Co5+YUOqQcA4IXrwDgL68C4rwvZebJkzxnp37q2tHlpVbmf17NJpPzjzx0cWhsAwDU+v/0dXAdQYdVCAmVo59LXg7Fl9aHfx0wBADwbF3OES6sUUPbFHgEA3ocAA5e2Ymz3CvXv9NpqSUy+6LB6AACugQADlxZbvXKF+idn5kj8OxukqMgjh3YBAP4fAQYuL8DPp8LPafi37+Tvyw85pB4AgPMRYODydk75k/zwTI8KP2/2up8l4efzcsf7P8rHG445pDYAgHMwCwkur2pwgL6FBvtLZk7Frn10/8eb9f2eUxnSt1UtqRNeyUFVAgCMxBEYuI2lT3aTSX2aXPXzfzxy1q71AACchwADtxETUVkeueU6mdyv6VU9/9n/7ZXUzBy71wUAMB4BBm7nL90ays+v9ZVODSt+yYGbXlstJ85nS0FhkUNqAwAYg0sJwO3dM2eTbPvlQoWf9/34W+T6yCoOqQkA4NjPb47AwO0tfLSL/DTlTxV+Xtxb6+VM+m9XSQcAuBcCDDzm+klX42+L9tq9FgCA4xFg4DHUuJiKWpd4VupPXCo93lgn+YyLAQC3QYCBx/Dz9ZFbbqh5Vc89fi5bGj23TDx0SBgAeBwWsgOKaTDpO33/yC0NZWLvJuLjU/HLGAAAHI8jMPAoMRH2WWn3w/XHZN1hFr4DAFdFgIFHmRDfRAa1qyvz/9Lxml+LRe8AwHVxCgkeJaxSgLxxT2u7vJZaubda5UDp1TzaLq8HALAfjsDAYz16y3WWr/u1qnVVrzHq3zv0LKXDKRdttqsVfdMv5V11jQCAq8NKvPBYhUUmOXAmU5rWqiqHki/K7e/9eM2vqa5mvXHibZKckSPf7j4j/9r8iySlXZb1E26VetVD7FI3AHizzHJ+fhNg4DWOpl6UuLc2OOS1/9ylvlwXWUXubFNbQoMDHPIeAOANMsv5+c0YGHiN6yOryot3NJcV+5Nl08/n7fraczf9ou83Hzsvsx5oa9fXBgD8EWNg4FWGd6kvn4/sJHFNoyQqNEjG9Ljerq+/dM+velzMlmPnJSe/UG9T9xeyGScDAPbEERh4pY+HtZMi02+r92blFliOoNhDr3c2yLGz2dKiTqgM61xfXl16UDIu58u25+IkLTtPDwhWs5vUlbCjw4Lt9r4A4E0IMPBKaoVdv/9fZLdWsRDxwZC28vj8ndf02iq8KPtOZ8oz/91j2d7h1e//0PeX1/tZvlbD0TJzCvRUcABA6Qgw8HrqtJIKHbc1jZT45tGy9W899bWRzmfnyaafz8lnm0867L0f/GSLPNy1vtzWJEom/HeP/HfHKVn4aGfpUD/CEmq4nAEA/BGzkIAyjF3wkyzedcbQ97z/phgdYqYtO6QHHvdteXXr2ACAu2EaNQEGdpSUdkm6TV/rtPdXp5q2/5Img+YkWLYtH9tNmkT//rt95dEatQ6OGuMDAO6EAEOAgZ2dz8qV/+08JZ0b1pD+71/7onj20qdFtNSoEiQLtp2UPi1qyT3t68r/dpzSR43ubltHRnVvKKsPpkrm5XxpFFVVbrmhpp4ZpW5qgb+u19eQaiGBltdTfxLMA5wBwGgeEWBmzZolM2bMkOTkZGndurW89957ctNNN5XruQQYOJK6vICnWffXWyUkyN9qsPFNDSLk7hvryKoDKZKZky8+4iPN64TqU1ot64TJc4v2yaoDydI6JlzmPnSTDj3ZuQWSnVcgkVV/HxytVi5evOu03N8hVoIDfSXI3+8P759XUCT5hUW6htKkXsyR6iFBFQ5YagaYGiBNMANcm9sHmC+++EKGDRsmc+bMkY4dO8o777wjCxculMTERImMjCzz+QQYOFKbl1ZK+qV8efWuFvJzarZ8uvG43v7KgBYyc/URSb2YK96uQ/1qsu2XCzbbujWqIT8cOWez7bMRHeWHI2clt6BIrqsZIlO+3q+3N4muqgdcT/pqr1X/J3s2kvfWHNFHltSRo4Y1QuTsxVxZuvdX6XJddZkztJ0cP5std87aqPs/17ep/JqRIz2a1JRdJ9Pl/o6xMvQfW+Xgr5n6tc5ezNHjj+pVryxVggJk4fYkqRocoPtvPZ4mryw9KHWrVZKYapVlZPcGElYpUN5dfUQevrm+1KwaJM1qhepB4HmFRfoUX/FTe2sTU+XZ/+6RyoF+8veBreRfCSekVd0wGdG1gfj7+crGo+ekoMgk5y7mys3X15DVh1L+f82i38KgOmp2LitXX9IiJTNXLlzKk0aRVfRzL/x/QPP19ZET57P1a4/s1lBP1VenE1U4DPTz1e1mF3Py9femqFOUqv7YiMpWpyJVn8U/nZY2MdWkZd0wvc6RWhbgUl6h7h8c8McwWpzqr+pT1wxT72UOkLkFhbLjxAVpExMulQNth1a1xEFI4G+vr2pS+/L7g6n68iB1q1UWV6T2vfo+I4od1bwWaj+pT+my9vO1Dvp3pVPObh9gVGjp0KGDvP/++/pxUVGRxMTEyBNPPCETJ04s8/kEGDiS+gP+a8ZlyxiUDYfPSqVAP8vsIfVBc9+HCbL7VIbV89QpnVMXLusPQgCuQQXC0+mXDX1PlRVU4K4IFc6PnfttmQZFHflUAXH/mUwprmHNEMtyDo72j+HtpWfTKLu+plsHmLy8PKlcubL897//lQEDBli2Dx8+XNLT0+Xrr7/+w3Nyc3P1rfgOUIGHAANnUf/n9O+EE3Jr40hZsPWk/Hj0nCx6/GYddG54bpn+P/QqQf6y5W895ZMfjktcs0h9HSVnDhYGgIoqvp6VePu1kM6dOyeFhYUSFWWd6tTjQ4cO2XzOtGnT5MUXXzSoQqBsapzHX7o11F9Pvr2ZVZta6+Xvyw/J3/o21WM+noprZGmb9/BNciTloj5V8fDNDfRphdBK/iWejgEAZxkXd4PT3tslA8zVmDRpkowfP/4PR2AAV6QO/aprMtmixnKo29DO9awGu37ywzG90N1TPRtJjyaR+nz1z2ezpHFUVT2mQ60orM5/bzp6Th74ZItM6tNEHrnlOsvzzTOP5m85qceGxERU1pc0UONNZqxIlLFxN8joz3fqwbTKynHdpXpIoIRWCpBGzy3T29S4kILC386Vn0y7pLd9PrKjvL7skGTlFMjoHtfLZ1tOyOO3Xi+VAvzk2f/t0Yfm1TiG7LxCPZ7j+4MplprU6504/9vrqNdU5+HL693BbWTepl9k58l06d+6tp4lpg6bJ2fmWPVT40LUKT9zDUrtsGA5k2HdD9bim0fJiv2//6yAK6lTVU/cZt/ryVWEx5xCuhJjYODNiopMVoM1K0LNIiprJpAjFR+IeOxsllQJ9rea0WRvCT+f1wGnd4to/TjjUr5+z+IDGtU+UYNrv9l9Rvq2iJbqVYJ0nUpZgyZVIAz097X5s1HXxbqcV6gDrblNvZyt11SDbFWYvCGqaoW/R1uDO9X3WdKMsKv9/Sq+vSK/g7YGkKptqm41APhalDSwVf1M1c/F39dHcvKL9KndK39W7qSolN+dq+HMVcDdegyMeRCvmjKtpk6bB/HGxsbKmDFjGMQLAICHcusxMIo6HaSOuLRv314HGTWNOjs7Wx566CFnlwYAAJzMZQPMfffdJ2fPnpWpU6fqhezatGkjy5cv/8PAXgAA4H1c9hTSteIUEgAAnvv57Z6jlQAAgFcjwAAAALdDgAEAAG6HAAMAANwOAQYAALgdAgwAAHA7BBgAAOB2CDAAAMDtEGAAAIDbIcAAAAC347LXQrpW5iskqCWJAQCAezB/bpd1pSOPDTAXL17U9zExMc4uBQAAXMXnuLomktddzLGoqEjOnDkjVatWFR8fH7unQxWMkpKSuFCkA7GfjcF+Ngb72RjsZ/ffzyqWqPBSu3Zt8fX19b4jMOqbrlu3rkPfQ/3Q+AfieOxnY7CfjcF+Ngb72b33c2lHXswYxAsAANwOAQYAALgdAsxVCAoKkueff17fw3HYz8ZgPxuD/WwM9rP37GePHcQLAAA8F0dgAACA2yHAAAAAt0OAAQAAbocAAwAA3A4BpoJmzZol9evXl+DgYOnYsaNs3brV2SW5rGnTpkmHDh30asiRkZEyYMAASUxMtOqTk5Mjo0ePlurVq0uVKlVk4MCBkpKSYtXn5MmT0q9fP6lcubJ+nQkTJkhBQYFVn3Xr1knbtm31iPjrr79e5s6dK97q9ddf16tPjx071rKN/Ww/p0+flgcffFDvy0qVKknLli1l+/btlnY1L2Lq1KlSq1Yt3R4XFydHjhyxeo20tDQZMmSIXgAsPDxcRowYIVlZWVZ99uzZI926ddN/a9SKp9OnTxdvUVhYKFOmTJEGDRrofXjdddfJyy+/bHVtHPZzxW3YsEH69++vV7hVfyMWL15s1W7kPl24cKE0adJE91H/hr777ruKf0NqFhLKZ8GCBabAwEDTp59+atq/f79p5MiRpvDwcFNKSoqzS3NJ8fHxpn/+85+mffv2mXbt2mXq27evKTY21pSVlWXp8+ijj5piYmJMq1evNm3fvt3UqVMnU5cuXSztBQUFphYtWpji4uJMP/30k+m7774z1ahRwzRp0iRLn2PHjpkqV65sGj9+vOnAgQOm9957z+Tn52davny5ydts3brVVL9+fVOrVq1MTz31lGU7+9k+0tLSTPXq1TP9+c9/Nm3ZskXvkxUrVpiOHj1q6fP666+bwsLCTIsXLzbt3r3bdMcdd5gaNGhgunz5sqVP7969Ta1btzZt3rzZ9MMPP5iuv/560/33329pz8jIMEVFRZmGDBmi//385z//MVWqVMn04YcfmrzBq6++aqpevbppyZIlpuPHj5sWLlxoqlKliundd9+19GE/V5z6d/3cc8+ZvvrqK5UETYsWLbJqN2qfbty4Uf/tmD59uv5bMnnyZFNAQIBp7969Ffp+CDAVcNNNN5lGjx5teVxYWGiqXbu2adq0aU6ty12kpqbqfzTr16/Xj9PT0/UvrfrjZHbw4EHdJyEhwfIPztfX15ScnGzpM3v2bFNoaKgpNzdXP37mmWdMzZs3t3qv++67Twcob3Lx4kVTo0aNTKtWrTLdcsstlgDDfrafZ5991tS1a9cS24uKikzR0dGmGTNmWLap/R8UFKT/kCvqD7ba99u2bbP0WbZsmcnHx8d0+vRp/fiDDz4wVatWzbLvze/duHFjkzfo16+f6eGHH7badvfdd+sPRYX9fO2uDDBG7tN7771X/4yL69ixo+mRRx6p0PfAKaRyysvLkx07duhDasWvt6QeJyQkOLU2d5GRkaHvIyIi9L3an/n5+Vb7VB1SjI2NtexTda8OL0ZFRVn6xMfH6wuJ7d+/39Kn+GuY+3jbz0WdIlKngK7cF+xn+/nmm2+kffv2cs899+jTbDfeeKN8/PHHlvbjx49LcnKy1X5S13RRp5uL72t16F29jpnqr/6ebNmyxdKne/fuEhgYaLWv1SnYCxcuiKfr0qWLrF69Wg4fPqwf7969W3788Ufp06ePfsx+tj8j96m9/pYQYMrp3Llz+rxs8T/winqsfugo++rgakzGzTffLC1atNDb1H5Tv+TqH0RJ+1Td29rn5rbS+qgP38uXL4s3WLBggezcuVOPO7oS+9l+jh07JrNnz5ZGjRrJihUr5LHHHpMnn3xS5s2bZ7WvSvs7oe5V+CnO399fB/uK/Dw82cSJE2Xw4ME6aAcEBOigqP5+qLEXCvvZ/ozcpyX1qeg+99irUcP1jg7s27dP/18U7Etdzv6pp56SVatW6QFxcGwQV//3+dprr+nH6oNV/V7PmTNHhg8f7uzyPMaXX34p8+fPl88//1yaN28uu3bt0gFGDT5lP8OMIzDlVKNGDfHz8/vDzA31ODo62ml1uYMxY8bIkiVLZO3atVK3bl3LdrXf1Km59PT0Evepure1z81tpfVRo+TVSHpPp04Rpaam6tlB6v+G1G39+vUyc+ZM/bX6Pxv2s32o2RnNmjWz2ta0aVM9g6v4virt74S6Vz+v4tRsLzW7oyI/D0+mZsCZj8KoU5tDhw6VcePGWY4wsp/tz8h9WlKfiu5zAkw5qUPw7dq10+dli//fmHrcuXNnp9bmqtQ4MRVeFi1aJGvWrNFTIotT+1MdHi6+T9V5UvVhYN6n6n7v3r1W/2jUkQb1oWn+IFF9ir+GuY+3/Fx69uyp95H6v1TzTR0lUIfbzV+zn+1DnQK9cikANU6jXr16+mv1O67+CBffT+oUmxofUHxfqzCpgqeZ+veh/p6o8QbmPmrKqxq7VHxfN27cWKpVqyae7tKlS3pcRXHqfyDVPlLYz/Zn5D6129+SCg359XJqGrUakT137lw9GnvUqFF6GnXxmRv43WOPPaan5K1bt87066+/Wm6XLl2ymt6rplavWbNGT+/t3Lmzvl05vbdXr156KraasluzZk2b03snTJigZ9fMmjXL66b3Xqn4LCSF/Wy/aer+/v56mu+RI0dM8+fP1/vks88+s5qKqv4ufP3116Y9e/aY7rzzTptTUW+88UY9FfvHH3/Us8eKT0VVsz/UVNShQ4fqqajqb496H0+d3nul4cOHm+rUqWOZRq2m/app/WomnBn7+epmKqplEtRNffy/9dZb+usTJ04Yuk/VNGr17+iNN97Qf0uef/55plEbQa19oT4I1Howalq1mgsP29Q/EFs3tTaMmfqH8fjjj+tpd+qX/K677tIhp7hffvnF1KdPH72WgPoj9vTTT5vy8/Ot+qxdu9bUpk0b/XNp2LCh1Xt4oysDDPvZfr799lsd9tT/zDRp0sT00UcfWbWr6ahTpkzRf8RVn549e5oSExOt+pw/f17/0Vdrm6ip6g899JD+cClOrcOhpmyr11Af5urDxVtkZmbq31/1tzY4OFj/rqn1S4pPzWU/V5z692vrb7IKjEbv0y+//NJ0ww036L8lanmGpUuXVvj78VH/uboDTgAAAM7BGBgAAOB2CDAAAMDtEGAAAIDbIcAAAAC3Q4ABAABuhwADAADcDgEGAAC4HQIMAABwOwQYAADgdggwAADA7RBgAACA2yHAAAAAcTf/B8e0KeeD98TyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6d80b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inducing_points_locations': tensor([[19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691],\n",
       "         [19.4223, 27.8497, 36.2772, 44.7046, 53.1320, 61.5594, 69.9868, 78.4143,\n",
       "          86.8417, 95.2691]], grad_fn=<AddBackward0>),\n",
       " 'inducing_point_values_loc': tensor([[-3.8692e-02,  1.7029e-02,  1.8167e-03,  2.9275e-02,  1.8044e-03,\n",
       "           4.8643e-02,  2.2019e-04,  2.3611e-02,  1.5401e-02, -2.4773e-02],\n",
       "         [-2.1922e-02, -2.0285e-02,  6.5540e-05,  1.6235e-03,  2.1049e-02,\n",
       "           2.7879e-02,  5.5261e-03, -5.8643e-03,  1.2631e-03, -1.2317e-02],\n",
       "         [ 2.9694e-03, -9.3483e-03,  9.0011e-03, -2.9042e-02,  4.1235e-04,\n",
       "           2.0005e-02, -3.1395e-02,  2.6870e-03, -2.2355e-03,  3.7209e-02],\n",
       "         [-3.8317e-02, -7.8430e-03, -1.7772e-02,  1.0694e-02, -2.4225e-03,\n",
       "          -1.4023e-02,  4.4904e-03,  3.7933e-02,  2.4261e-03, -2.6392e-02],\n",
       "         [ 3.2283e-03, -4.1785e-02, -4.5327e-03, -1.9173e-02, -8.6005e-03,\n",
       "          -1.3901e-02, -6.5094e-03,  3.3014e-02, -4.5138e-03, -2.9061e-03],\n",
       "         [ 1.3792e-02, -3.3670e-02,  3.0895e-02, -4.6202e-03,  2.7394e-02,\n",
       "           1.3579e-02, -5.2172e-03, -4.4851e-03, -9.1256e-03, -9.7927e-03],\n",
       "         [-1.3366e-02, -3.7997e-02,  1.0200e-02, -2.6719e-02,  7.2882e-03,\n",
       "          -1.8293e-02,  1.4461e-02, -1.1345e-02,  4.9424e-02, -1.1342e-02],\n",
       "         [ 3.2136e-02,  2.8707e-02,  1.3868e-02,  9.4314e-03,  1.5795e-03,\n",
       "           9.5494e-03, -1.8923e-03,  2.8369e-02,  1.2547e-03, -5.2755e-02],\n",
       "         [-7.6186e-03, -3.0377e-02,  3.9085e-02,  3.7058e-02, -3.0788e-02,\n",
       "          -2.3965e-02, -1.2939e-02,  1.8419e-02,  7.9701e-03, -4.4648e-03],\n",
       "         [-1.8678e-02, -6.5802e-03,  1.8086e-02, -5.4198e-03, -3.4408e-02,\n",
       "           5.0918e-03, -3.1372e-03,  4.6248e-04,  9.6994e-03,  2.3151e-02],\n",
       "         [ 1.9539e-02, -2.1671e-03, -1.8232e-02, -9.3324e-03, -1.4464e-02,\n",
       "           1.6497e-02, -5.2932e-03,  1.9688e-02,  1.8694e-02, -3.6670e-03],\n",
       "         [ 3.5547e-02,  1.3272e-02, -1.0346e-02, -4.2612e-02,  5.3232e-02,\n",
       "           3.5267e-02,  1.0843e-02,  7.3317e-03, -2.0502e-03,  1.0385e-02],\n",
       "         [ 1.8781e-02, -1.1107e-02, -3.5236e-02,  6.3303e-02,  1.4342e-02,\n",
       "           3.0682e-02,  1.2225e-02,  5.2777e-02,  4.1141e-03, -4.7711e-03],\n",
       "         [ 1.7276e-02,  3.4956e-03, -1.2479e-02,  1.9019e-02,  1.4373e-02,\n",
       "           1.4627e-02, -2.5189e-02,  7.7810e-03, -4.8595e-03,  5.7877e-02],\n",
       "         [ 3.3754e-02,  1.1093e-02, -5.7265e-03,  1.7283e-02,  2.1515e-03,\n",
       "          -2.7217e-02, -7.5132e-03,  2.7316e-03,  7.2926e-03, -3.1521e-03],\n",
       "         [-4.5787e-02, -3.3698e-02, -9.8574e-03, -3.8571e-02,  4.1439e-02,\n",
       "          -2.4430e-02,  1.6367e-02, -3.1396e-02, -2.1475e-02,  8.4911e-03],\n",
       "         [-3.1882e-02, -5.3905e-03,  6.5496e-03,  2.7007e-02, -1.3305e-02,\n",
       "          -1.9612e-02, -3.6556e-02,  6.0874e-03,  2.2914e-02, -7.9409e-03],\n",
       "         [-3.0849e-02,  5.3473e-02, -1.9802e-02,  6.9405e-03,  3.1890e-02,\n",
       "          -2.5538e-02, -2.1709e-02, -3.8695e-02, -3.6649e-02, -6.1915e-03],\n",
       "         [ 5.9267e-02,  1.2539e-02,  2.5414e-02, -2.8691e-02, -3.1578e-02,\n",
       "           3.7537e-03,  5.4398e-02, -1.1010e-02,  2.3346e-03,  1.8160e-02],\n",
       "         [-8.7382e-03,  6.9809e-04,  5.7869e-03,  3.8464e-02,  9.6539e-03,\n",
       "          -2.2576e-02, -6.7659e-03, -4.2962e-02,  1.3100e-02, -8.0480e-03],\n",
       "         [ 4.3771e-03,  3.9927e-03,  1.6637e-03, -3.3786e-03, -1.1803e-02,\n",
       "           8.1137e-04,  3.3128e-02,  3.5828e-03, -5.6237e-03, -1.9159e-03],\n",
       "         [ 4.4884e-02,  4.0466e-03,  1.0132e-02, -9.6921e-04, -4.9304e-02,\n",
       "          -1.1022e-03, -9.4003e-03, -1.7365e-02,  2.7749e-02,  2.9223e-02],\n",
       "         [ 7.6702e-03,  1.0621e-02, -1.2516e-03, -7.4494e-04,  2.0322e-02,\n",
       "          -9.1301e-03, -3.0608e-02,  4.8815e-02, -2.4065e-02, -2.0117e-02],\n",
       "         [ 2.0403e-03,  5.5056e-03,  1.1203e-02, -5.5963e-03,  1.0811e-02,\n",
       "          -2.5116e-02,  9.1540e-03,  2.5811e-02, -4.2577e-02, -9.0015e-03],\n",
       "         [ 9.1937e-04, -3.2233e-02,  3.0219e-02,  3.2267e-02,  9.4398e-05,\n",
       "          -8.0115e-03, -9.9543e-03,  1.5521e-02,  4.1733e-02, -1.0199e-02],\n",
       "         [ 2.0778e-02, -3.4219e-02, -8.0487e-03,  1.5062e-02, -1.6763e-02,\n",
       "          -9.2240e-03,  3.2589e-03, -4.0904e-02,  3.6119e-02, -2.0820e-02],\n",
       "         [ 9.6242e-03,  3.8650e-03, -2.0399e-02, -1.6314e-02, -2.1268e-02,\n",
       "           6.1054e-02,  2.2351e-03,  3.5864e-02,  5.6079e-03,  2.9294e-02],\n",
       "         [ 6.2083e-04, -5.1364e-02, -3.7350e-02, -2.0306e-02, -3.1651e-02,\n",
       "           1.8050e-02, -7.4751e-03, -1.6450e-02,  6.9389e-04, -4.2847e-02],\n",
       "         [ 2.5603e-02, -2.6504e-02, -2.4839e-03,  1.4476e-02,  1.2493e-02,\n",
       "           6.4594e-03,  1.2646e-03,  7.7419e-03,  3.0266e-02, -2.4467e-02],\n",
       "         [-6.9692e-03, -1.3455e-02, -1.7364e-02,  7.3014e-03,  1.0580e-02,\n",
       "          -7.6603e-03, -1.1945e-02,  3.2571e-03, -6.6582e-03, -4.2369e-02],\n",
       "         [-5.0987e-03, -4.2071e-03,  1.0573e-02,  1.2520e-02,  5.7896e-03,\n",
       "           5.6442e-03, -2.1435e-02, -1.2522e-02, -1.1626e-02,  1.3756e-02],\n",
       "         [ 7.5681e-03, -1.2776e-02, -1.0348e-02, -2.4053e-02,  8.3940e-03,\n",
       "           8.9154e-03, -2.8084e-02, -4.1497e-02,  1.6829e-02, -1.8805e-02],\n",
       "         [ 1.3248e-02,  1.1033e-02,  3.0088e-02,  4.5136e-02, -8.8907e-03,\n",
       "          -4.7351e-02,  1.4026e-02,  2.6206e-02, -2.8261e-02,  2.7233e-02],\n",
       "         [ 8.7939e-03, -2.8202e-02, -2.2420e-02, -6.5048e-03,  2.4568e-02,\n",
       "          -9.7632e-03,  5.0477e-02,  3.7817e-03, -2.7866e-02, -2.1257e-02],\n",
       "         [ 3.1810e-02,  5.7068e-03, -1.6804e-03, -2.1205e-02, -4.2990e-02,\n",
       "          -1.2765e-03, -1.9579e-02, -1.1336e-02,  2.1900e-03,  5.0748e-02],\n",
       "         [-2.6949e-03,  2.4961e-02,  2.8975e-02, -1.5124e-02,  1.6662e-02,\n",
       "           3.1903e-02,  3.0010e-02, -1.4418e-02,  2.1671e-02, -9.7772e-03],\n",
       "         [ 3.6223e-02, -2.6510e-02,  3.4285e-02, -4.5158e-02,  3.1678e-02,\n",
       "          -1.2418e-02,  7.1253e-02,  2.5883e-02,  2.6023e-02,  1.9486e-02],\n",
       "         [ 1.0050e-02, -4.3856e-02, -1.7156e-02,  3.9941e-02, -3.1484e-02,\n",
       "           1.4995e-02,  1.8884e-02,  1.6280e-02,  3.5662e-02, -2.6189e-02],\n",
       "         [ 2.4746e-02, -2.0540e-03,  5.4457e-03,  1.6977e-03,  2.6480e-02,\n",
       "          -1.0089e-02,  1.2982e-02,  8.6737e-03,  4.9796e-03, -2.0097e-02],\n",
       "         [-2.4021e-02, -2.1170e-02,  6.8209e-03,  1.2858e-02, -3.4132e-02,\n",
       "          -2.5776e-02, -1.6160e-02,  1.5583e-02,  2.9141e-02,  1.5411e-02],\n",
       "         [ 1.7410e-03, -1.4837e-02, -1.4200e-02,  5.3680e-02, -2.7716e-02,\n",
       "           8.0347e-03,  1.6260e-02, -2.6544e-02,  1.5462e-03,  4.3338e-02],\n",
       "         [ 7.1187e-03, -1.2139e-02, -2.1427e-03, -2.0586e-02, -2.4957e-02,\n",
       "          -3.6314e-02,  1.4450e-02, -2.5885e-02, -2.0357e-03, -1.2110e-02],\n",
       "         [ 1.0550e-02,  2.2562e-02, -5.8299e-02,  2.8474e-02, -4.7565e-02,\n",
       "          -3.5156e-02,  2.7574e-02,  4.5874e-02, -1.4889e-03, -3.0304e-02],\n",
       "         [ 2.2220e-03,  3.4085e-02,  4.4589e-02, -4.3995e-03, -1.4013e-02,\n",
       "           7.5112e-03, -1.3285e-02, -1.3338e-02, -1.3640e-02, -1.3518e-02],\n",
       "         [-1.1626e-02, -4.4317e-03,  2.9118e-02,  2.1985e-02,  3.9672e-02,\n",
       "          -3.8671e-03, -1.4303e-03, -1.1389e-02,  1.1219e-02,  2.2284e-02],\n",
       "         [-1.6802e-02,  2.9011e-02, -1.8606e-02, -1.5467e-02,  1.7903e-02,\n",
       "          -5.9751e-04,  1.3467e-02, -2.5878e-02,  2.2152e-02, -7.8646e-03],\n",
       "         [ 4.0569e-02, -1.0401e-02, -7.1922e-02,  8.5754e-03,  1.3674e-02,\n",
       "          -2.1993e-02, -3.5677e-03, -4.6220e-02, -1.9932e-02,  7.8896e-03],\n",
       "         [-3.4523e-02, -8.4326e-03, -3.5372e-02,  8.8448e-03, -2.9876e-02,\n",
       "          -7.5267e-03,  6.9348e-03, -1.1744e-02,  1.5472e-02,  2.6259e-02],\n",
       "         [ 1.3277e-02,  1.9028e-02, -5.8106e-04,  1.5092e-02,  2.1088e-02,\n",
       "          -4.8951e-02,  1.6660e-02,  1.4519e-02, -4.8912e-02,  2.9163e-02],\n",
       "         [ 3.4385e-03, -1.3135e-02,  3.1194e-02, -3.9863e-02,  7.8256e-03,\n",
       "          -1.4489e-02,  8.4437e-03, -1.1189e-02, -1.2844e-02, -2.9101e-03],\n",
       "         [ 1.3440e-02,  3.3163e-02,  3.5228e-02,  1.6303e-02, -5.2522e-03,\n",
       "           2.7766e-02, -2.4888e-02, -4.0146e-02, -3.0903e-02,  1.2501e-02],\n",
       "         [-1.7679e-02, -1.0629e-02, -2.0958e-02,  7.2419e-03,  2.3955e-02,\n",
       "          -3.6356e-02, -3.0432e-02,  1.3412e-02,  7.2704e-03, -3.2247e-02],\n",
       "         [ 4.0728e-03,  3.6294e-03,  4.4516e-02, -3.1086e-02,  1.4372e-03,\n",
       "          -2.2413e-02,  5.0893e-02,  2.0103e-02, -4.0416e-02, -1.0259e-02],\n",
       "         [ 2.6000e-02, -2.1987e-02, -7.8004e-03, -5.3472e-03, -2.8740e-02,\n",
       "           3.1882e-03, -2.1794e-02,  2.2960e-02,  2.1968e-02,  3.7409e-02],\n",
       "         [-3.9959e-02,  1.0244e-02, -5.1469e-03, -1.2921e-02,  3.6509e-02,\n",
       "          -8.5877e-03, -2.9062e-02,  1.4583e-02,  5.1952e-02, -3.0821e-02],\n",
       "         [-2.8111e-02,  1.7614e-02,  7.0931e-03, -2.9020e-02, -1.6143e-02,\n",
       "           2.4214e-02, -1.9527e-02, -1.2928e-02,  2.7046e-03, -2.5035e-02],\n",
       "         [ 8.6013e-03, -8.4175e-03, -1.2155e-02,  1.9351e-02,  2.3156e-04,\n",
       "           2.5082e-02,  1.3871e-02, -1.4361e-02, -1.2013e-02, -1.5743e-02],\n",
       "         [ 5.5252e-03,  2.6370e-02,  2.1435e-02,  1.5278e-02,  2.4024e-02,\n",
       "          -1.6054e-02,  5.8824e-02, -3.0939e-03,  2.3225e-02,  5.7158e-03],\n",
       "         [ 3.7011e-02, -6.8360e-04, -1.0848e-02,  2.1513e-02, -4.1054e-03,\n",
       "          -3.2486e-02,  6.0034e-03, -2.1549e-02, -1.8671e-02, -1.8920e-02],\n",
       "         [-4.5940e-05,  2.1927e-02, -2.3579e-02,  3.6595e-02, -2.7256e-02,\n",
       "          -2.2073e-02, -1.7870e-02,  2.0333e-02, -5.4514e-02,  3.0674e-02],\n",
       "         [-2.1822e-02, -8.1774e-03,  5.7895e-02, -1.5995e-02,  4.0244e-03,\n",
       "           3.3163e-02,  1.3062e-02,  4.3732e-03, -2.0672e-02,  2.9579e-02],\n",
       "         [ 6.0083e-03, -1.8009e-02, -1.0023e-03,  1.0866e-02,  2.3757e-02,\n",
       "           3.0719e-02,  4.8955e-03, -1.8305e-02, -1.5595e-02, -4.1171e-03],\n",
       "         [ 2.3572e-02, -5.3792e-02, -3.2299e-02, -3.5270e-02,  3.1148e-02,\n",
       "           1.8310e-03,  2.1018e-02, -1.6375e-03, -2.2468e-02, -4.0351e-02],\n",
       "         [ 3.7067e-02, -1.7722e-02, -2.0056e-02, -3.3883e-03, -3.2957e-02,\n",
       "           5.4914e-03, -3.1550e-03, -1.4904e-02,  2.6279e-02,  1.5185e-03],\n",
       "         [-1.0955e-02,  1.1484e-03,  4.1119e-03, -2.4290e-02,  2.9757e-03,\n",
       "           9.4513e-03,  2.0130e-02,  1.8718e-02, -7.1397e-03,  1.0866e-02],\n",
       "         [ 2.3012e-03,  5.4114e-03, -5.2226e-03,  2.1454e-02, -7.0338e-03,\n",
       "          -3.2607e-02, -1.7340e-02, -8.7485e-03, -1.5376e-02, -2.7342e-02],\n",
       "         [-3.7734e-02,  3.5186e-03, -7.9180e-02,  8.3840e-03,  1.3646e-02,\n",
       "          -4.5397e-02,  2.9523e-03,  2.7038e-02,  4.2548e-02, -3.6847e-02],\n",
       "         [-1.2135e-02,  5.6099e-04,  3.3405e-04,  2.1504e-04, -3.6806e-03,\n",
       "          -5.0450e-02, -2.1419e-02, -3.2168e-02,  1.4036e-02, -2.6421e-02],\n",
       "         [-1.1790e-02,  6.9217e-03,  3.5318e-02, -4.3654e-02,  1.2487e-02,\n",
       "          -2.7797e-02,  4.1155e-02,  6.9695e-04, -1.7438e-02,  2.8971e-02],\n",
       "         [-2.3404e-02,  2.8536e-02,  2.6052e-02, -1.6196e-03, -2.2637e-02,\n",
       "          -2.9397e-02, -2.1110e-02,  2.5139e-02, -1.4995e-02,  7.5427e-04],\n",
       "         [ 9.2675e-04,  5.1896e-03, -3.2678e-02,  9.4952e-03, -1.0411e-02,\n",
       "           1.3685e-02, -4.9020e-03,  5.7084e-03, -2.3352e-02, -4.9426e-03],\n",
       "         [ 3.7208e-02,  1.6012e-02,  2.4816e-02,  3.5405e-02, -3.4045e-03,\n",
       "          -6.3474e-03,  3.1344e-02,  6.8098e-03, -1.8719e-02, -2.4069e-02],\n",
       "         [-1.8412e-02, -9.6309e-03,  6.2480e-03, -3.3674e-03, -3.8960e-04,\n",
       "           1.4704e-02,  4.7777e-02, -1.0877e-02,  2.6345e-02,  2.2797e-03],\n",
       "         [ 7.9725e-04, -7.4779e-03, -6.1523e-02, -2.4672e-02, -1.5887e-02,\n",
       "           3.3442e-03,  1.5042e-02, -3.0240e-02,  8.4632e-03, -1.8554e-02],\n",
       "         [-2.6240e-02, -1.5256e-02, -4.0737e-02,  1.5109e-02,  1.0277e-03,\n",
       "          -1.3147e-02, -3.1593e-02,  3.4793e-03,  1.4529e-03, -2.8118e-03],\n",
       "         [-2.4582e-02,  9.9435e-03,  1.2195e-02,  3.3017e-04, -4.4686e-02,\n",
       "           2.4301e-02, -2.6533e-02, -2.5142e-02, -2.5864e-02, -5.5783e-03],\n",
       "         [ 4.3250e-03, -2.7260e-03, -2.1215e-02, -5.2737e-03, -9.9956e-03,\n",
       "          -1.1085e-02,  3.1304e-03, -3.9583e-02, -1.7249e-02,  3.5340e-02],\n",
       "         [ 1.5275e-02, -1.7803e-03, -1.4307e-02, -1.7863e-02,  1.4921e-02,\n",
       "          -1.0085e-02,  3.6076e-03,  3.7743e-02, -2.4940e-02,  3.4922e-02],\n",
       "         [ 7.1814e-03,  2.4128e-02,  5.5899e-03,  3.7523e-02, -4.5728e-04,\n",
       "           9.5116e-03,  1.8923e-02,  3.5257e-03, -1.5342e-02,  2.2250e-02],\n",
       "         [-1.5245e-02,  2.6920e-02,  5.0485e-03,  2.7233e-02, -1.9326e-02,\n",
       "           8.5164e-03,  2.3933e-02, -1.6768e-02,  1.3777e-02, -2.4272e-02],\n",
       "         [ 2.1601e-02, -1.1298e-02,  3.4306e-02, -7.5744e-03, -5.8543e-03,\n",
       "          -2.2824e-02,  1.5849e-03, -9.3630e-03,  3.0772e-02, -3.9194e-02],\n",
       "         [ 4.4845e-03,  1.0483e-02,  1.2992e-02, -5.8458e-03, -3.5187e-02,\n",
       "           2.7456e-03, -3.3410e-03,  2.2360e-02, -3.7892e-02,  9.3474e-03],\n",
       "         [-1.7430e-02, -1.0690e-02,  3.8476e-02,  6.0604e-03, -1.9083e-02,\n",
       "           2.9009e-02,  1.2604e-02,  2.7939e-02,  6.6236e-03, -2.5671e-02],\n",
       "         [-1.9076e-02,  4.3918e-03,  3.4426e-02,  9.3135e-03, -1.6075e-02,\n",
       "          -2.2031e-02, -3.2120e-02, -1.3512e-02, -4.1974e-03,  2.2924e-02],\n",
       "         [-1.1194e-02,  6.0965e-02, -1.6850e-02,  1.9571e-02, -3.2566e-02,\n",
       "          -1.3495e-02, -2.5914e-02,  3.2973e-03,  2.6616e-02,  3.6904e-02],\n",
       "         [-1.8565e-02,  3.2479e-02, -1.7201e-02, -1.5779e-02, -1.7247e-02,\n",
       "           1.1956e-02, -1.1884e-06,  2.7393e-02, -1.3648e-02,  3.5740e-03],\n",
       "         [-2.2761e-02, -2.5616e-02, -2.8274e-02,  6.9537e-03,  1.0429e-02,\n",
       "           1.8341e-02,  1.4479e-02,  1.2153e-02, -3.9984e-03,  9.1925e-04],\n",
       "         [-4.7251e-02, -1.4427e-02,  2.0349e-02,  8.9515e-03, -3.5036e-02,\n",
       "          -2.0768e-02, -4.1746e-02,  1.3109e-02,  3.3766e-03,  3.3586e-02],\n",
       "         [-1.4620e-02, -1.7799e-02,  3.1594e-02, -3.9061e-02,  4.6552e-03,\n",
       "           2.0728e-02, -1.9516e-03, -1.4259e-04,  5.4838e-03, -1.5853e-02],\n",
       "         [-1.4026e-03,  1.1527e-02,  9.0921e-03, -7.3381e-02, -2.3473e-02,\n",
       "          -1.4513e-02, -3.8674e-03,  3.9545e-03,  2.4548e-02,  9.4077e-03],\n",
       "         [ 3.9015e-02, -4.2108e-02,  5.7655e-03, -1.7021e-02,  8.0290e-03,\n",
       "          -6.4633e-03, -1.9976e-02,  2.7082e-02,  2.4756e-02, -2.7577e-02],\n",
       "         [-9.7402e-03,  3.5858e-02, -9.0924e-03,  4.9162e-02,  3.5248e-02,\n",
       "          -2.3903e-02,  1.2611e-02, -1.7446e-02, -3.4839e-02, -1.4245e-02],\n",
       "         [-4.1158e-03,  2.5450e-02, -6.3862e-03,  9.0579e-04, -1.2385e-02,\n",
       "           1.3427e-02, -6.1258e-02, -3.1472e-03, -2.6877e-02,  8.8254e-03],\n",
       "         [ 1.8149e-02, -2.3744e-02, -7.4730e-03,  1.5186e-02,  2.0556e-02,\n",
       "           1.2779e-03,  1.0981e-02, -1.3424e-02,  1.0057e-02,  2.1971e-02],\n",
       "         [-1.8148e-02, -6.6756e-03,  2.0385e-02,  3.3753e-04,  3.5909e-03,\n",
       "           1.0053e-02,  3.5701e-02, -1.1879e-02, -4.4454e-04,  1.6036e-02],\n",
       "         [ 3.5153e-02,  5.1316e-02, -1.5215e-02, -2.1215e-02, -1.8878e-02,\n",
       "          -4.2314e-03,  1.3986e-02, -5.5282e-02,  2.6978e-02, -3.0444e-02],\n",
       "         [ 2.0188e-02, -1.6633e-02,  8.5596e-03, -3.3750e-03,  1.9077e-02,\n",
       "           6.2222e-03,  4.1952e-02,  4.4276e-02, -6.5780e-03, -3.7104e-02],\n",
       "         [-5.1324e-02, -2.9125e-03,  1.8517e-02,  3.3486e-03,  2.1905e-02,\n",
       "          -8.7066e-03,  3.8885e-02,  2.4527e-02,  1.7814e-02, -5.9591e-03],\n",
       "         [-1.3151e-02, -4.8836e-03, -2.6982e-02, -2.5974e-02, -2.5140e-02,\n",
       "          -3.3830e-03,  1.2325e-03,  2.6592e-02, -1.2568e-02,  2.2105e-02],\n",
       "         [ 2.0653e-02, -4.3660e-03, -1.5789e-02, -2.7774e-02, -2.4997e-02,\n",
       "           2.8169e-02, -4.1873e-02, -1.0024e-02,  4.1768e-02,  4.7711e-03]],\n",
       "        requires_grad=True),\n",
       " 'inducing_point_values_scale_unconstrained': tensor([[0.5233, 0.5155, 0.5698, 0.5329, 0.5394, 0.5508, 0.5705, 0.5571, 0.5282,\n",
       "          0.5548],\n",
       "         [0.5240, 0.5691, 0.5357, 0.5486, 0.5784, 0.5544, 0.5630, 0.5851, 0.5405,\n",
       "          0.5494],\n",
       "         [0.5759, 0.5431, 0.5447, 0.5784, 0.5546, 0.5709, 0.5491, 0.5457, 0.5529,\n",
       "          0.5451],\n",
       "         [0.5045, 0.5274, 0.5245, 0.5393, 0.5492, 0.5626, 0.5111, 0.5438, 0.5387,\n",
       "          0.5246],\n",
       "         [0.5397, 0.5397, 0.5303, 0.5459, 0.5154, 0.4908, 0.5787, 0.5155, 0.5501,\n",
       "          0.5759],\n",
       "         [0.5637, 0.5258, 0.5053, 0.5726, 0.5124, 0.5311, 0.5733, 0.5607, 0.5385,\n",
       "          0.5566],\n",
       "         [0.5336, 0.5632, 0.5687, 0.5934, 0.5743, 0.5454, 0.5550, 0.5085, 0.5421,\n",
       "          0.5210],\n",
       "         [0.5538, 0.5606, 0.5684, 0.5181, 0.5745, 0.5733, 0.5421, 0.5884, 0.5612,\n",
       "          0.5081],\n",
       "         [0.5609, 0.5406, 0.5826, 0.5192, 0.5248, 0.5308, 0.5896, 0.5203, 0.5482,\n",
       "          0.5288],\n",
       "         [0.5431, 0.5614, 0.5363, 0.5163, 0.5271, 0.5360, 0.5489, 0.5103, 0.5419,\n",
       "          0.5189],\n",
       "         [0.5314, 0.5110, 0.5436, 0.5486, 0.5225, 0.5261, 0.4560, 0.5408, 0.5323,\n",
       "          0.5218],\n",
       "         [0.5235, 0.5342, 0.4998, 0.5318, 0.5352, 0.5530, 0.5414, 0.5560, 0.5602,\n",
       "          0.5491],\n",
       "         [0.5222, 0.5693, 0.5223, 0.5445, 0.5123, 0.5074, 0.5497, 0.5553, 0.5465,\n",
       "          0.5266],\n",
       "         [0.5037, 0.5297, 0.5701, 0.5299, 0.5690, 0.5231, 0.5291, 0.5834, 0.5488,\n",
       "          0.5291],\n",
       "         [0.5720, 0.5497, 0.5828, 0.5372, 0.5699, 0.5344, 0.5565, 0.5381, 0.5361,\n",
       "          0.5223],\n",
       "         [0.5450, 0.5267, 0.5509, 0.5283, 0.5071, 0.5282, 0.5803, 0.5461, 0.5379,\n",
       "          0.5450],\n",
       "         [0.5675, 0.5130, 0.5784, 0.5368, 0.5397, 0.5287, 0.5734, 0.5536, 0.5459,\n",
       "          0.5261],\n",
       "         [0.5287, 0.5397, 0.5651, 0.5289, 0.5357, 0.5179, 0.5507, 0.5680, 0.5461,\n",
       "          0.5467],\n",
       "         [0.5088, 0.5189, 0.5675, 0.5163, 0.5496, 0.5769, 0.5529, 0.5365, 0.5548,\n",
       "          0.5668],\n",
       "         [0.5362, 0.5397, 0.5664, 0.5420, 0.5544, 0.5287, 0.5527, 0.5633, 0.5701,\n",
       "          0.5975],\n",
       "         [0.5584, 0.5563, 0.5071, 0.5263, 0.5380, 0.5612, 0.5571, 0.5038, 0.5258,\n",
       "          0.5570],\n",
       "         [0.5268, 0.5732, 0.5661, 0.5208, 0.5122, 0.5377, 0.5809, 0.5867, 0.5480,\n",
       "          0.5554],\n",
       "         [0.5309, 0.5133, 0.5363, 0.5345, 0.4917, 0.5531, 0.5641, 0.5539, 0.5812,\n",
       "          0.5692],\n",
       "         [0.5061, 0.5544, 0.5411, 0.5386, 0.5152, 0.5249, 0.5788, 0.5797, 0.5714,\n",
       "          0.5275],\n",
       "         [0.5365, 0.5267, 0.5244, 0.5389, 0.5443, 0.5788, 0.5361, 0.5038, 0.5291,\n",
       "          0.5003],\n",
       "         [0.5202, 0.4974, 0.5426, 0.5556, 0.5513, 0.5308, 0.5312, 0.5341, 0.5320,\n",
       "          0.5569],\n",
       "         [0.5364, 0.5505, 0.5281, 0.5534, 0.5410, 0.5710, 0.5269, 0.5174, 0.5722,\n",
       "          0.5332],\n",
       "         [0.5201, 0.5422, 0.5529, 0.5664, 0.5632, 0.5770, 0.5433, 0.5352, 0.5024,\n",
       "          0.5632],\n",
       "         [0.5632, 0.5406, 0.5903, 0.5596, 0.5328, 0.5413, 0.5474, 0.5845, 0.5357,\n",
       "          0.5252],\n",
       "         [0.5621, 0.5432, 0.5219, 0.5612, 0.5694, 0.5367, 0.5924, 0.5152, 0.5765,\n",
       "          0.5235],\n",
       "         [0.5499, 0.5330, 0.5089, 0.5621, 0.5546, 0.5116, 0.5446, 0.5263, 0.5309,\n",
       "          0.5304],\n",
       "         [0.5233, 0.5121, 0.5584, 0.5007, 0.5431, 0.5082, 0.5566, 0.4762, 0.5289,\n",
       "          0.5410],\n",
       "         [0.4952, 0.5395, 0.5388, 0.4966, 0.5729, 0.5545, 0.5120, 0.5557, 0.5353,\n",
       "          0.5477],\n",
       "         [0.5308, 0.5346, 0.5655, 0.5293, 0.5361, 0.5215, 0.5263, 0.5443, 0.5337,\n",
       "          0.5370],\n",
       "         [0.5672, 0.5364, 0.5386, 0.5651, 0.5445, 0.5613, 0.5548, 0.5682, 0.5209,\n",
       "          0.5529],\n",
       "         [0.5426, 0.5274, 0.5343, 0.5107, 0.5602, 0.5640, 0.5879, 0.5285, 0.5429,\n",
       "          0.5325],\n",
       "         [0.5503, 0.5523, 0.5244, 0.4954, 0.5106, 0.5464, 0.5413, 0.5473, 0.5336,\n",
       "          0.5790],\n",
       "         [0.5449, 0.5539, 0.5810, 0.5375, 0.5286, 0.5591, 0.5382, 0.5974, 0.5309,\n",
       "          0.5265],\n",
       "         [0.5765, 0.5706, 0.5285, 0.5209, 0.5407, 0.5555, 0.5165, 0.5802, 0.5084,\n",
       "          0.5206],\n",
       "         [0.5189, 0.5387, 0.5459, 0.5643, 0.5346, 0.5156, 0.5636, 0.5415, 0.5496,\n",
       "          0.5516],\n",
       "         [0.5819, 0.5439, 0.5387, 0.5023, 0.5433, 0.5922, 0.5249, 0.5649, 0.5342,\n",
       "          0.5169],\n",
       "         [0.5413, 0.5274, 0.5810, 0.5538, 0.5434, 0.5281, 0.5500, 0.5698, 0.5484,\n",
       "          0.5272],\n",
       "         [0.5026, 0.5393, 0.5472, 0.5534, 0.5887, 0.5384, 0.5506, 0.5545, 0.5150,\n",
       "          0.5378],\n",
       "         [0.5342, 0.5247, 0.5574, 0.5544, 0.5502, 0.5333, 0.5771, 0.5678, 0.5225,\n",
       "          0.5212],\n",
       "         [0.5273, 0.5532, 0.5520, 0.5565, 0.5512, 0.5581, 0.5910, 0.5275, 0.6035,\n",
       "          0.5444],\n",
       "         [0.5676, 0.5390, 0.5455, 0.5357, 0.5643, 0.5247, 0.5358, 0.5598, 0.5231,\n",
       "          0.5355],\n",
       "         [0.5559, 0.5364, 0.5482, 0.5683, 0.5032, 0.5754, 0.5165, 0.5691, 0.5594,\n",
       "          0.5412],\n",
       "         [0.5419, 0.5257, 0.5819, 0.5535, 0.5170, 0.5691, 0.5321, 0.5542, 0.5545,\n",
       "          0.5325],\n",
       "         [0.5064, 0.5535, 0.5320, 0.5608, 0.5317, 0.5549, 0.5534, 0.5758, 0.5669,\n",
       "          0.5570],\n",
       "         [0.5304, 0.5164, 0.5925, 0.5032, 0.5388, 0.5333, 0.5520, 0.5243, 0.5330,\n",
       "          0.5664],\n",
       "         [0.5638, 0.5694, 0.5774, 0.5320, 0.5446, 0.5279, 0.5282, 0.5293, 0.5578,\n",
       "          0.5482],\n",
       "         [0.5434, 0.5205, 0.5367, 0.6065, 0.5720, 0.5503, 0.5031, 0.5517, 0.5573,\n",
       "          0.5401],\n",
       "         [0.5255, 0.5565, 0.5383, 0.5601, 0.5410, 0.4957, 0.5214, 0.5622, 0.5490,\n",
       "          0.5436],\n",
       "         [0.5462, 0.5339, 0.5064, 0.5537, 0.5217, 0.5567, 0.5270, 0.5409, 0.5307,\n",
       "          0.5439],\n",
       "         [0.5170, 0.5741, 0.5195, 0.5238, 0.5411, 0.5232, 0.5466, 0.5094, 0.5831,\n",
       "          0.5354],\n",
       "         [0.5312, 0.5227, 0.5437, 0.4887, 0.5547, 0.5609, 0.5160, 0.5205, 0.5506,\n",
       "          0.4985],\n",
       "         [0.4662, 0.5389, 0.5409, 0.5386, 0.5343, 0.5647, 0.5505, 0.5448, 0.5167,\n",
       "          0.5153],\n",
       "         [0.5225, 0.5507, 0.5252, 0.5075, 0.5107, 0.6105, 0.5668, 0.5296, 0.5232,\n",
       "          0.5377],\n",
       "         [0.4995, 0.5800, 0.5453, 0.5351, 0.5702, 0.5364, 0.5118, 0.5366, 0.5743,\n",
       "          0.4879],\n",
       "         [0.5344, 0.5424, 0.5595, 0.5596, 0.5166, 0.5471, 0.5601, 0.5654, 0.5330,\n",
       "          0.5506],\n",
       "         [0.5383, 0.5408, 0.4982, 0.5530, 0.5483, 0.5420, 0.5251, 0.5627, 0.5296,\n",
       "          0.5327],\n",
       "         [0.5306, 0.5227, 0.5122, 0.5848, 0.5564, 0.5578, 0.6003, 0.5385, 0.5330,\n",
       "          0.5615],\n",
       "         [0.5288, 0.5467, 0.5314, 0.5503, 0.5426, 0.5323, 0.5627, 0.5585, 0.5528,\n",
       "          0.4978],\n",
       "         [0.5314, 0.5628, 0.5249, 0.5638, 0.5105, 0.5489, 0.5279, 0.5623, 0.5443,\n",
       "          0.5221],\n",
       "         [0.5625, 0.5134, 0.5085, 0.5757, 0.5175, 0.5564, 0.5097, 0.5160, 0.5336,\n",
       "          0.5508],\n",
       "         [0.5501, 0.5452, 0.5507, 0.5549, 0.5257, 0.5456, 0.5537, 0.5151, 0.5289,\n",
       "          0.5678],\n",
       "         [0.5601, 0.5575, 0.5850, 0.5274, 0.5077, 0.5857, 0.5402, 0.5310, 0.5371,\n",
       "          0.5511],\n",
       "         [0.5692, 0.5205, 0.5402, 0.5637, 0.5929, 0.5449, 0.5520, 0.4866, 0.5404,\n",
       "          0.5803],\n",
       "         [0.5341, 0.5110, 0.5278, 0.5601, 0.5317, 0.5311, 0.5161, 0.5204, 0.5158,\n",
       "          0.5442],\n",
       "         [0.5837, 0.5707, 0.5454, 0.5758, 0.5368, 0.5513, 0.5497, 0.5517, 0.5691,\n",
       "          0.5212],\n",
       "         [0.5299, 0.5106, 0.5487, 0.5485, 0.5507, 0.5702, 0.5265, 0.5295, 0.5154,\n",
       "          0.5486],\n",
       "         [0.5650, 0.5047, 0.5766, 0.5487, 0.6023, 0.5640, 0.5708, 0.5328, 0.5671,\n",
       "          0.5868],\n",
       "         [0.5880, 0.5215, 0.5516, 0.5621, 0.5019, 0.5821, 0.5559, 0.5790, 0.5128,\n",
       "          0.4999],\n",
       "         [0.5946, 0.5904, 0.5357, 0.5271, 0.5616, 0.5160, 0.5558, 0.5472, 0.5254,\n",
       "          0.5571],\n",
       "         [0.5744, 0.4983, 0.5105, 0.5535, 0.5536, 0.5903, 0.5496, 0.5605, 0.5720,\n",
       "          0.5154],\n",
       "         [0.5453, 0.5767, 0.5266, 0.5488, 0.5026, 0.5366, 0.5542, 0.5580, 0.5246,\n",
       "          0.5391],\n",
       "         [0.5276, 0.5588, 0.5205, 0.5230, 0.5153, 0.5362, 0.5323, 0.5375, 0.4900,\n",
       "          0.5331],\n",
       "         [0.5450, 0.5684, 0.5238, 0.5043, 0.5324, 0.5790, 0.5049, 0.5653, 0.5370,\n",
       "          0.5591],\n",
       "         [0.5601, 0.5463, 0.5509, 0.5300, 0.5845, 0.5816, 0.5116, 0.5232, 0.5804,\n",
       "          0.5543],\n",
       "         [0.5133, 0.5404, 0.5316, 0.5491, 0.5292, 0.4916, 0.5370, 0.5451, 0.5911,\n",
       "          0.5535],\n",
       "         [0.4826, 0.5720, 0.5463, 0.5119, 0.5349, 0.4901, 0.5661, 0.5756, 0.5011,\n",
       "          0.5189],\n",
       "         [0.5430, 0.5749, 0.5748, 0.5186, 0.5751, 0.5662, 0.5260, 0.5564, 0.5368,\n",
       "          0.5651],\n",
       "         [0.5121, 0.5448, 0.5205, 0.5480, 0.5692, 0.5160, 0.5511, 0.5294, 0.5133,\n",
       "          0.5559],\n",
       "         [0.5808, 0.5275, 0.5195, 0.5162, 0.5585, 0.5046, 0.5524, 0.5794, 0.5173,\n",
       "          0.5720],\n",
       "         [0.5463, 0.5765, 0.5436, 0.5597, 0.5519, 0.5461, 0.5084, 0.5295, 0.5496,\n",
       "          0.5259],\n",
       "         [0.5473, 0.5175, 0.5240, 0.5464, 0.4883, 0.5473, 0.5216, 0.5768, 0.5584,\n",
       "          0.5220],\n",
       "         [0.4915, 0.5124, 0.5009, 0.5561, 0.5477, 0.5117, 0.5578, 0.5691, 0.5627,\n",
       "          0.5763],\n",
       "         [0.5526, 0.5473, 0.5493, 0.5117, 0.5126, 0.5614, 0.5101, 0.5399, 0.5129,\n",
       "          0.4971],\n",
       "         [0.5164, 0.5412, 0.5202, 0.5384, 0.5767, 0.5001, 0.4931, 0.5527, 0.5695,\n",
       "          0.4897],\n",
       "         [0.5206, 0.5596, 0.5788, 0.5395, 0.5699, 0.5724, 0.5377, 0.5451, 0.5065,\n",
       "          0.5543],\n",
       "         [0.5485, 0.5710, 0.5375, 0.5548, 0.5244, 0.5162, 0.5438, 0.5383, 0.5645,\n",
       "          0.5417],\n",
       "         [0.5691, 0.5344, 0.5579, 0.5513, 0.5592, 0.5148, 0.5328, 0.5074, 0.5684,\n",
       "          0.5265],\n",
       "         [0.5556, 0.5116, 0.5746, 0.5399, 0.5671, 0.5547, 0.5353, 0.5241, 0.5206,\n",
       "          0.5197],\n",
       "         [0.5134, 0.5254, 0.5153, 0.5184, 0.5655, 0.5394, 0.5559, 0.5092, 0.5488,\n",
       "          0.5195],\n",
       "         [0.5441, 0.5273, 0.5860, 0.5305, 0.5965, 0.5432, 0.5221, 0.5680, 0.5633,\n",
       "          0.5399],\n",
       "         [0.5478, 0.5353, 0.5206, 0.5529, 0.5425, 0.5313, 0.5495, 0.5074, 0.5444,\n",
       "          0.5437],\n",
       "         [0.5364, 0.5295, 0.5535, 0.5590, 0.5178, 0.5365, 0.5637, 0.4677, 0.5499,\n",
       "          0.5357],\n",
       "         [0.5175, 0.5336, 0.5517, 0.5352, 0.5775, 0.5307, 0.5607, 0.5446, 0.5146,\n",
       "          0.5781],\n",
       "         [0.5579, 0.5364, 0.5961, 0.4943, 0.5226, 0.5157, 0.5271, 0.5605, 0.5278,\n",
       "          0.5734],\n",
       "         [0.5573, 0.5486, 0.5393, 0.5357, 0.5318, 0.5100, 0.5654, 0.5354, 0.5092,\n",
       "          0.5186]], requires_grad=True),\n",
       " 'length_scale_alpha_unconstrained': tensor([0.4410, 0.4596, 0.4140, 0.4212, 0.4244, 0.4417, 0.4398, 0.4222, 0.4181,\n",
       "         0.4479, 0.4221, 0.4502, 0.4089, 0.4358, 0.4424, 0.4248, 0.4370, 0.4810,\n",
       "         0.4622, 0.3946, 0.4292, 0.3998, 0.4235, 0.4337, 0.4503, 0.4017, 0.4157,\n",
       "         0.3971, 0.4504, 0.4280, 0.4093, 0.4177, 0.4273, 0.4758, 0.4212, 0.4463,\n",
       "         0.4315, 0.4264, 0.4224, 0.4520, 0.4147, 0.4070, 0.4307, 0.4419, 0.4706,\n",
       "         0.4458, 0.4305, 0.4609, 0.4968, 0.3933, 0.4270, 0.4315, 0.4021, 0.4321,\n",
       "         0.4461, 0.4503, 0.4586, 0.4604, 0.4493, 0.4301, 0.4500, 0.4070, 0.4304,\n",
       "         0.4663, 0.4049, 0.4372, 0.4141, 0.4646, 0.4118, 0.4734, 0.4656, 0.4301,\n",
       "         0.4153, 0.4350, 0.4174, 0.4613, 0.4365, 0.3932, 0.3921, 0.4363, 0.4519,\n",
       "         0.4056, 0.4395, 0.4248, 0.4065, 0.4406, 0.4316, 0.4447, 0.4357, 0.4611,\n",
       "         0.4527, 0.4049, 0.4214, 0.4788, 0.4727, 0.4002, 0.4409, 0.4399, 0.4800,\n",
       "         0.3966], requires_grad=True),\n",
       " 'length_scale_beta_unconstrained': tensor([0.4426, 0.4222, 0.3260, 0.4125, 0.3841, 0.3979, 0.4307, 0.4069, 0.3716,\n",
       "         0.4147, 0.3687, 0.4199, 0.4188, 0.3507, 0.3809, 0.4267, 0.4359, 0.3678,\n",
       "         0.4097, 0.4489, 0.3929, 0.3738, 0.3852, 0.3674, 0.3801, 0.3931, 0.4381,\n",
       "         0.4277, 0.4037, 0.4046, 0.4520, 0.4218, 0.4180, 0.4308, 0.4087, 0.3468,\n",
       "         0.4084, 0.3701, 0.4348, 0.4136, 0.4160, 0.4279, 0.4043, 0.4251, 0.3741,\n",
       "         0.3943, 0.3866, 0.4213, 0.3569, 0.3955, 0.4060, 0.4376, 0.3935, 0.3967,\n",
       "         0.4722, 0.4102, 0.3547, 0.3805, 0.4145, 0.3990, 0.3765, 0.4355, 0.4379,\n",
       "         0.4193, 0.4023, 0.4239, 0.3809, 0.4198, 0.4557, 0.3561, 0.3633, 0.4160,\n",
       "         0.3869, 0.3737, 0.3654, 0.4194, 0.3618, 0.3920, 0.4425, 0.3849, 0.3361,\n",
       "         0.4436, 0.4328, 0.4033, 0.4603, 0.3900, 0.4184, 0.4254, 0.3728, 0.3793,\n",
       "         0.4367, 0.4010, 0.3724, 0.4106, 0.4104, 0.4225, 0.4175, 0.4063, 0.3829,\n",
       "         0.4216], requires_grad=True),\n",
       " 'variance_alpha_unconstrained': tensor([0.4656, 0.3990, 0.3866, 0.4264, 0.4448, 0.4326, 0.3962, 0.4665, 0.4286,\n",
       "         0.4398, 0.4561, 0.4145, 0.4275, 0.4430, 0.4321, 0.4503, 0.4102, 0.4203,\n",
       "         0.4601, 0.4212, 0.3946, 0.4568, 0.4265, 0.4050, 0.4407, 0.4324, 0.4653,\n",
       "         0.4429, 0.4667, 0.4260, 0.4364, 0.4481, 0.4240, 0.4445, 0.4260, 0.4230,\n",
       "         0.4639, 0.4369, 0.4421, 0.4151, 0.4375, 0.4326, 0.4463, 0.4613, 0.4390,\n",
       "         0.4130, 0.4457, 0.4282, 0.5000, 0.4420, 0.4314, 0.4363, 0.4453, 0.4392,\n",
       "         0.3954, 0.4303, 0.4165, 0.4339, 0.4457, 0.3812, 0.4188, 0.3915, 0.3973,\n",
       "         0.4734, 0.4032, 0.4296, 0.4365, 0.4108, 0.4322, 0.4366, 0.3835, 0.4152,\n",
       "         0.4062, 0.4389, 0.4383, 0.4693, 0.4671, 0.4553, 0.4159, 0.4248, 0.4570,\n",
       "         0.4383, 0.4456, 0.4421, 0.4682, 0.4726, 0.4491, 0.4338, 0.4354, 0.4749,\n",
       "         0.4116, 0.4432, 0.4463, 0.4232, 0.4300, 0.4341, 0.4163, 0.4311, 0.4357,\n",
       "         0.4229], requires_grad=True),\n",
       " 'variance_beta_unconstrained': tensor([0.4103, 0.3978, 0.4226, 0.3887, 0.3782, 0.3909, 0.4012, 0.3795, 0.3999,\n",
       "         0.4072, 0.3898, 0.3915, 0.4094, 0.3972, 0.4422, 0.4025, 0.3845, 0.3960,\n",
       "         0.3982, 0.4109, 0.4004, 0.4391, 0.3771, 0.4216, 0.4221, 0.4297, 0.4036,\n",
       "         0.4187, 0.3843, 0.4260, 0.3621, 0.4253, 0.4123, 0.3841, 0.3817, 0.4040,\n",
       "         0.3913, 0.3978, 0.3497, 0.4159, 0.4066, 0.3621, 0.3731, 0.3583, 0.4082,\n",
       "         0.3837, 0.4233, 0.4399, 0.4379, 0.4396, 0.3575, 0.4188, 0.3776, 0.4161,\n",
       "         0.4339, 0.4064, 0.4181, 0.3937, 0.3932, 0.4017, 0.3014, 0.4232, 0.4043,\n",
       "         0.3875, 0.4243, 0.3945, 0.4201, 0.4189, 0.3880, 0.4043, 0.4310, 0.4081,\n",
       "         0.4485, 0.4065, 0.4045, 0.4124, 0.3814, 0.3590, 0.3717, 0.3928, 0.3947,\n",
       "         0.4115, 0.4167, 0.4319, 0.4521, 0.3868, 0.4290, 0.4037, 0.3959, 0.4030,\n",
       "         0.3907, 0.4125, 0.3632, 0.4344, 0.3925, 0.4162, 0.4123, 0.4027, 0.4240,\n",
       "         0.3868], requires_grad=True),\n",
       " 'disp_alpha_unconstrained': tensor([0.4164, 0.4191, 0.4449, 0.4275, 0.4230, 0.4314, 0.4216, 0.4550, 0.4145,\n",
       "         0.4680, 0.4524, 0.4269, 0.4346, 0.4480, 0.4371, 0.4047, 0.4615, 0.4438,\n",
       "         0.4193, 0.4400, 0.3739, 0.4061, 0.4431, 0.4624, 0.4303, 0.4223, 0.4377,\n",
       "         0.3819, 0.4628, 0.4145, 0.4158, 0.4154, 0.4490, 0.4423, 0.4351, 0.4486,\n",
       "         0.4528, 0.4455, 0.4506, 0.4175, 0.4581, 0.4500, 0.4223, 0.4383, 0.4366,\n",
       "         0.4378, 0.4309, 0.4266, 0.4856, 0.4121, 0.4904, 0.4358, 0.4306, 0.3827,\n",
       "         0.4384, 0.4426, 0.4362, 0.4320, 0.4460, 0.4000, 0.4715, 0.4473, 0.4062,\n",
       "         0.4640, 0.4090, 0.3954, 0.4797, 0.4981, 0.4420, 0.4441, 0.4160, 0.4598,\n",
       "         0.4177, 0.4279, 0.3924, 0.4095, 0.4593, 0.3993, 0.4660, 0.3920, 0.4620,\n",
       "         0.4099, 0.4331, 0.4703, 0.3798, 0.4283, 0.4737, 0.4230, 0.4215, 0.4544,\n",
       "         0.4305, 0.4740, 0.4369, 0.4192, 0.4239, 0.4264, 0.4161, 0.4355, 0.4359,\n",
       "         0.4115], requires_grad=True),\n",
       " 'disp_beta_unconstrained': tensor([0.3981, 0.3622, 0.3860, 0.4066, 0.4241, 0.4078, 0.3999, 0.4340, 0.4076,\n",
       "         0.3408, 0.4217, 0.3824, 0.3967, 0.3806, 0.3789, 0.4281, 0.3886, 0.3950,\n",
       "         0.4165, 0.4407, 0.3946, 0.4183, 0.3753, 0.3769, 0.4437, 0.3922, 0.3891,\n",
       "         0.4392, 0.4216, 0.3938, 0.4261, 0.3805, 0.3976, 0.3970, 0.3970, 0.3875,\n",
       "         0.4151, 0.3773, 0.3970, 0.4212, 0.4054, 0.3747, 0.3666, 0.4199, 0.4152,\n",
       "         0.4422, 0.3996, 0.4010, 0.4031, 0.3494, 0.3979, 0.4403, 0.4059, 0.4276,\n",
       "         0.4239, 0.4493, 0.3661, 0.4357, 0.3892, 0.4080, 0.3867, 0.4012, 0.3785,\n",
       "         0.4530, 0.4019, 0.4293, 0.3613, 0.3971, 0.4128, 0.4189, 0.4441, 0.3829,\n",
       "         0.4025, 0.3810, 0.3595, 0.3988, 0.3636, 0.3997, 0.4025, 0.4351, 0.3846,\n",
       "         0.3759, 0.4125, 0.4247, 0.4094, 0.3792, 0.4192, 0.3960, 0.4058, 0.3682,\n",
       "         0.4203, 0.3973, 0.3899, 0.3645, 0.3840, 0.4342, 0.4119, 0.3746, 0.4288,\n",
       "         0.3792], requires_grad=True)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(pyro.get_param_store())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian-process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
